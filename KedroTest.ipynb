{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KedroTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hafezgh/Hate-Speech-Detection-in-Social-Media/blob/main/KedroTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h88slt1K0WqW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "\n",
        "! pip install kedro transformers datasets emoji wandb\n",
        "! git clone https://github.com/hafezgh/Hate-Speech-Detection-in-Social-Media.git\n",
        "os.chdir('/content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runs"
      ],
      "metadata": {
        "id": "sCOEq-EPtTx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Davidson dataset"
      ],
      "metadata": {
        "id": "69rNt22FtmlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classic"
      ],
      "metadata": {
        "id": "5VixufEvwNrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN\n",
        "! kedro run --params BERT_model:cnn,training_type:classic,device:cuda,dataset:davidson,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "LN5YxbqwwP21",
        "outputId": "6142259d-a6f0-478e-b813-99b538e62be3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:24:37,157 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:24:37,177 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:24:37,628 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:24:40,813 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:24:40,814 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:24:40,814 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:24:40,853 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:24:40,865 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:24:40,907 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:24:41,892 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:24:41,895 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:24:41,895 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:24:41,896 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:24:41,896 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:24:41,896 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:24:41,896 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 6196/6196 [00:16<00:00, 374.22ba/s]\n",
            "2022-02-15 14:25:00,797 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,799 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:25:00,799 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,799 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,800 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,800 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,800 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:25:00,827 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,828 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,828 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,830 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:25:00,830 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,831 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,831 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,831 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,831 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,831 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,831 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,831 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,831 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,832 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:25:00,832 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "Epoch 1 / 3:\n",
            "Batch 11/310 |███>................................................................................................| 3.55% complete, loss=0.00, accuracy=02022-02-15 14:25:22,028 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN\n",
        "! kedro run --params BERT_model:rnn,training_type:classic,device:cuda,dataset:davidson,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "3BuS8aBPwdNv",
        "outputId": "48707f52-36f9-4398-d6a9-6c9f85d79d6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:25:56,113 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:25:56,133 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:25:56,581 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:25:59,813 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:25:59,814 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:25:59,814 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:25:59,853 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:25:59,866 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:25:59,915 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:26:00,912 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:00,915 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:26:00,915 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:00,916 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:26:00,916 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:26:00,916 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:26:00,916 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 6196/6196 [00:16<00:00, 368.67ba/s]\n",
            "2022-02-15 14:26:20,098 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,099 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:26:20,100 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,100 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,100 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,100 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,100 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:26:20,127 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,128 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,128 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,130 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:26:20,130 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,130 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,131 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,131 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,131 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,131 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,131 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,131 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,131 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,132 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:20,133 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "Epoch 1 / 3:\n",
            "Batch 18/310 |█████>..............................................................................................| 5.81% complete, loss=0.00, accuracy=02022-02-15 14:26:35,894 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep FC\n",
        "! kedro run --params BERT_model:deep_fc,training_type:classic,device:cuda,dataset:davidson,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "hqsb8fUMwdI7",
        "outputId": "40a1b3d3-2ab2-458e-95d6-11de54ad171f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:26:40,636 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:26:40,653 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:26:41,097 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:26:44,318 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:44,318 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:26:44,318 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:26:44,358 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:26:44,370 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:26:44,411 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:26:45,386 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:45,389 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:26:45,389 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:26:45,389 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:26:45,390 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:26:45,390 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:26:45,390 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 6196/6196 [00:16<00:00, 370.38ba/s]\n",
            "2022-02-15 14:27:04,476 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,478 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:27:04,478 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,479 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,479 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,479 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,479 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:27:04,506 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,507 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,508 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,509 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:27:04,509 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,510 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,510 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,510 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,510 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,510 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,510 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,510 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,511 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,511 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:04,511 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "Epoch 1 / 3:\n",
            "Batch 12/310 |███>................................................................................................| 3.87% complete, loss=0.00, accuracy=02022-02-15 14:27:16,885 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shallow FC\n",
        "! kedro run --params BERT_model:shallow_fc,training_type:classic,device:cuda,dataset:davidson,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "gU95EdfMwdLa",
        "outputId": "29c19683-d372-4e21-b877-6d523c072360",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:27:21,315 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:27:21,333 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:27:21,776 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:27:24,910 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:24,910 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:27:24,910 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:27:24,949 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:27:24,961 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:27:25,004 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:27:26,010 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:26,013 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:27:26,013 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:26,014 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:27:26,014 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:27:26,014 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:27:26,014 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 6196/6196 [00:16<00:00, 367.54ba/s]\n",
            "2022-02-15 14:27:45,236 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,238 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:27:45,239 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,239 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,239 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,240 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,240 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:27:45,269 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,270 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,270 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,272 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:27:45,272 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,272 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,273 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,273 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,273 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,273 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,273 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,273 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,274 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,274 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:27:45,274 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "Epoch 1 / 3:\n",
            "Batch 24/310 |███████>............................................................................................| 7.74% complete, loss=0.00, accuracy=02022-02-15 14:28:04,073 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformers"
      ],
      "metadata": {
        "id": "K4AHWH7Mtn_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN\n",
        "! kedro run --params BERT_model:cnn,training_type:transformers,device:cuda,dataset:davidson,model_name:bert-base-uncased"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br3KFc4w69sI",
        "outputId": "dcc06ed3-1dfa-48e6-9950-f228dd4b5b52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:15:39,156 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:15:39,173 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "/content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/src/irisP/pipelines/data_engineering/nodes.py:96: DeprecationWarning: invalid escape sequence \\*\n",
            "  emoticons = [':-)', ':)', '(:', '(-:', ':))', '((:', ':-D', ':D', 'X-D', 'XD', 'xD', 'xD', '<3', '</3', ':\\*',\n",
            "/content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/src/irisP/pipelines/data_engineering/nodes.py:110: DeprecationWarning: invalid escape sequence \\w\n",
            "  users = re.findall(\"[@]\\w+\", text)\n",
            "2022-02-15 14:15:39,610 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:15:42,917 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:15:42,917 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:15:42,917 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:15:42,960 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:15:42,974 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:15:43,020 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:15:44,047 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:15:44,050 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:15:44,050 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:15:44,051 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:15:44,051 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:15:44,051 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:15:44,051 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 6196/6196 [00:16<00:00, 370.47ba/s]\n",
            "2022-02-15 14:16:03,128 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,130 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:16:03,130 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,131 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,131 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,131 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,131 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:16:03,162 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,162 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,163 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,165 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:16:03,165 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,165 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,165 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,165 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,165 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,165 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,166 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,166 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,166 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,166 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:16:03,167 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 19826\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 930\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "  3% 24/930 [00:31<19:31,  1.29s/it]2022-02-15 14:17:01,474 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n",
            "  3% 24/930 [00:32<20:28,  1.36s/it]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 387... (failed 1).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/wandb/offline-run-20220215_141625-xfbqx1i0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20220215_141625-xfbqx1i0/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN\n",
        "! kedro run --params BERT_model:rnn,training_type:transformers,device:cuda,dataset:davidson,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "qOPVuhJ9t9Hz",
        "outputId": "4255cec5-e48e-4829-faa5-487e5f1e1d86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:17:12,612 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:17:12,629 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:17:13,081 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:17:16,282 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:16,283 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:17:16,283 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:17:16,325 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:17:16,338 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:17:16,382 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:17:17,371 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:17,374 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:17:17,374 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:17,375 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:17:17,375 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:17:17,375 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:17:17,375 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 6196/6196 [00:16<00:00, 369.28ba/s]\n",
            "2022-02-15 14:17:36,516 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,518 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:17:36,518 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,518 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,519 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,519 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,519 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:17:36,546 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,547 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,548 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,549 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:17:36,549 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,550 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,550 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,550 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,550 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,550 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,550 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,550 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,550 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,551 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:17:36,551 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 19826\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 930\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "  4% 39/930 [00:14<05:20,  2.78it/s]2022-02-15 14:18:17,594 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n",
            "  4% 39/930 [00:14<05:29,  2.70it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 455... (failed 1).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/wandb/offline-run-20220215_141759-7zivo2a9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20220215_141759-7zivo2a9/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep FC\n",
        "! kedro run --params BERT_model:deep_fc,training_type:transformers,device:cuda,dataset:davidson,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "oM2YLsJOuFBC",
        "outputId": "57140296-a6d8-479e-d241-1c5a0b016213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:18:23,928 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:18:23,948 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:18:24,397 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:18:27,585 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:27,585 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:18:27,586 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:18:27,625 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:18:27,638 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:18:27,679 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:18:28,740 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:28,743 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:18:28,743 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:28,743 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:18:28,743 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:18:28,744 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:18:28,744 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 6196/6196 [00:17<00:00, 363.70ba/s]\n",
            "2022-02-15 14:18:48,135 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,137 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:18:48,137 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,137 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,138 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,138 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,138 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:18:48,167 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,167 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,168 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,170 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:18:48,170 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,170 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,170 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,170 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,170 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,170 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,171 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,171 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,171 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,171 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:18:48,172 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 19826\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 930\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "  5% 43/930 [00:15<05:15,  2.81it/s]2022-02-15 14:19:17,411 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n",
            "  5% 43/930 [00:15<05:25,  2.73it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 517... (failed 1).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/wandb/offline-run-20220215_141858-27hlulaj\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20220215_141858-27hlulaj/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shallow FC\n",
        "! kedro run --params BERT_model:shallow_fc,training_type:transformers,device:cuda,dataset:davidson,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "9nD_KE3JuIij",
        "outputId": "e4b3486f-a0a4-4a1f-bc42-8d474f0046cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:19:23,700 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:19:23,718 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:19:24,169 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:19:27,308 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:27,308 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:19:27,308 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:19:27,349 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:19:27,361 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:19:27,404 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:19:28,387 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:28,390 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:19:28,390 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:28,391 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:19:28,391 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:19:28,391 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:19:28,391 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 6196/6196 [00:16<00:00, 366.87ba/s]\n",
            "2022-02-15 14:19:47,640 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,641 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:19:47,642 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,642 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,642 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,643 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,643 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:19:47,670 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,671 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,671 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,673 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:19:47,673 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,673 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,673 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,674 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,674 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,674 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,674 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,674 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,674 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,675 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:19:47,675 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 19826\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 930\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "  4% 35/930 [00:12<05:18,  2.81it/s]2022-02-15 14:20:13,972 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n",
            "  4% 35/930 [00:12<05:26,  2.74it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 579... (failed 1).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/wandb/offline-run-20220215_141957-3p9xb87y\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20220215_141957-3p9xb87y/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multilingual dataset"
      ],
      "metadata": {
        "id": "2VD5TUwZyOdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classic"
      ],
      "metadata": {
        "id": "h2DxbvFV0rFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN\n",
        "! kedro run --params BERT_model:cnn,training_type:classic,device:cuda,dataset:multilingual,model_name:bert-base-multilingual-cased"
      ],
      "metadata": {
        "id": "_ljJ2U4o0txL",
        "outputId": "6252aba0-c31e-4d56-c80f-407bd54c23c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:41:22,041 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:41:22,058 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:41:22,506 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:41:25,742 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:25,742 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:41:25,742 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:41:25,783 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:41:25,795 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:41:25,842 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:41:25,843 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:25,844 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:41:25,845 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:25,845 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:41:25,845 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:41:25,845 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:41:25,845 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 2762/2762 [00:09<00:00, 280.03ba/s]\n",
            "2022-02-15 14:41:38,870 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,872 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:41:38,873 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,873 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,873 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,873 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,873 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:41:38,891 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,891 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,892 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,893 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:41:38,893 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,894 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,894 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,894 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,894 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,894 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,894 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,894 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,894 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,895 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:38,895 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "Epoch 1 / 3:\n",
            "Batch 4/139 |██>.................................................................................................| 2.88% complete, loss=0.00, accuracy=02022-02-15 14:41:51,397 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN\n",
        "! kedro run --params BERT_model:rnn,training_type:classic,device:cuda,dataset:multilingual,model_name:bert-base-multilingual-cased"
      ],
      "metadata": {
        "id": "hP5FgvlZ0uZx",
        "outputId": "671ea713-60b3-4cee-c143-34594c96eb7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:41:56,033 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:41:56,051 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:41:56,495 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:41:59,715 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:59,715 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:41:59,715 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:41:59,759 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:41:59,772 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:41:59,819 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:41:59,820 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:59,822 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:41:59,822 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:41:59,822 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:41:59,822 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:41:59,822 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:41:59,823 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 2762/2762 [00:09<00:00, 282.36ba/s]\n",
            "2022-02-15 14:42:12,712 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,714 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:42:12,714 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,715 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,715 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,715 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,715 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:42:12,733 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,733 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,734 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,735 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:42:12,735 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,736 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,736 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,736 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,736 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,736 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,736 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,736 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,737 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,737 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:12,737 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "Epoch 1 / 3:\n",
            "Batch 8/139 |█████>..............................................................................................| 5.76% complete, loss=0.00, accuracy=02022-02-15 14:42:23,526 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep FC\n",
        "! kedro run --params BERT_model:deep_fc,training_type:classic,device:cuda,dataset:multilingual,model_name:bert-base-multilingual-cased"
      ],
      "metadata": {
        "id": "5LQ-3WzN0uPk",
        "outputId": "08099c4a-200e-419a-f1d9-9f4751370061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:42:26,653 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:42:26,671 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:42:27,119 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:42:30,319 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:30,319 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:42:30,319 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:42:30,359 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:42:30,371 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:42:30,415 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:42:30,416 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:30,418 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:42:30,418 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:30,418 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:42:30,419 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:42:30,419 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:42:30,419 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 2762/2762 [00:09<00:00, 277.06ba/s]\n",
            "2022-02-15 14:42:43,529 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,531 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:42:43,531 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,531 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,532 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,532 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,532 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:42:43,550 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,551 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,552 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,553 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:42:43,553 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,554 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,554 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,554 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,554 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,554 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,554 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,554 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,555 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,555 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:43,555 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "Epoch 1 / 3:\n",
            "Batch 7/139 |█████>..............................................................................................| 5.04% complete, loss=0.00, accuracy=02022-02-15 14:42:53,594 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shallow FC\n",
        "! kedro run --params BERT_model:shallow_fc,training_type:classic,device:cuda,dataset:multilingual,model_name:bert-base-multilingual-cased"
      ],
      "metadata": {
        "id": "B4HEc97L0uNX",
        "outputId": "62e49b9e-358d-4d48-ebcd-f254784b0554",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:42:56,324 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:42:56,345 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:42:56,794 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:42:59,964 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:42:59,964 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:42:59,964 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:43:00,004 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:43:00,016 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:43:00,058 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:43:00,060 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:43:00,061 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:43:00,061 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:43:00,062 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:43:00,062 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:43:00,062 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:43:00,062 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 2762/2762 [00:09<00:00, 282.55ba/s]\n",
            "2022-02-15 14:43:12,924 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,926 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:43:12,926 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,927 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,927 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,927 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,927 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:43:12,946 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,947 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,947 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,949 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:43:12,949 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,949 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,949 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,949 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,949 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,949 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,950 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,950 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,950 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,950 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:43:12,951 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "Epoch 1 / 3:\n",
            "Batch 7/139 |█████>..............................................................................................| 5.04% complete, loss=0.00, accuracy=02022-02-15 14:43:23,309 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformers"
      ],
      "metadata": {
        "id": "we17B7d-0zBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN\n",
        "! kedro run --params BERT_model:cnn,training_type:transformers,device:cuda,dataset:multilingual,model_name:bert-base-multilingual-cased"
      ],
      "metadata": {
        "id": "tdpmKR90zL9i",
        "outputId": "881252c2-940e-465d-aa4b-9ab9c900d2be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:36:28,059 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:36:28,078 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:36:28,534 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:36:31,838 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:31,838 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:36:31,839 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:36:31,878 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:36:31,891 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:36:31,933 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:36:31,934 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:31,936 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:36:31,936 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:31,936 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:36:31,937 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:36:31,937 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:36:31,937 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 2762/2762 [00:10<00:00, 275.68ba/s]\n",
            "2022-02-15 14:36:45,071 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,073 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:36:45,073 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,073 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,074 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,074 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,074 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:36:45,091 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,092 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,092 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,093 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:36:45,094 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,094 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,094 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,094 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,094 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,094 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,094 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,095 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,095 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,095 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:36:45,096 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8837\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 417\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "  1% 6/417 [00:07<09:00,  1.32s/it]2022-02-15 14:37:11,351 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n",
            "  1% 6/417 [00:08<09:20,  1.36s/it]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 967... (failed 1).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/wandb/offline-run-20220215_143659-1krxo54l\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20220215_143659-1krxo54l/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN\n",
        "! kedro run --params BERT_model:rnn,training_type:transformers,device:cuda,dataset:multilingual,model_name:bert-base-multilingual-cased"
      ],
      "metadata": {
        "id": "GcSAUDxQzL6-",
        "outputId": "0f45d3c7-21d3-463d-b640-fc419696980b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:37:17,452 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:37:17,470 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:37:17,928 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:37:21,231 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:21,231 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:37:21,232 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:37:21,273 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:37:21,286 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:37:21,329 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:37:21,330 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:21,331 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:37:21,332 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:21,332 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:37:21,332 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:37:21,332 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:37:21,332 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 2762/2762 [00:09<00:00, 282.25ba/s]\n",
            "2022-02-15 14:37:34,259 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,261 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:37:34,262 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,262 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,262 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,262 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,262 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:37:34,284 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,284 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,285 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,286 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:37:34,286 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,286 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,286 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,286 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,287 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,287 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,287 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,287 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,287 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,288 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:37:34,288 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8837\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 417\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "  4% 16/417 [00:06<02:30,  2.67it/s]2022-02-15 14:38:00,963 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n",
            "  4% 16/417 [00:06<02:40,  2.49it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1027... (failed 1).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/wandb/offline-run-20220215_143751-vg6jsmdb\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20220215_143751-vg6jsmdb/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep FC\n",
        "! kedro run --params BERT_model:deep_fc,training_type:transformers,device:cuda,dataset:multilingual,model_name:bert-base-multilingual-cased"
      ],
      "metadata": {
        "id": "rq8O_N85zLz2",
        "outputId": "93db135d-7c00-412c-bc4f-8183a1bc8ae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:38:08,494 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:38:08,511 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:38:08,968 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:38:12,233 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:12,233 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:38:12,233 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:38:12,274 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:38:12,287 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:38:12,329 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:38:12,331 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:12,332 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:38:12,332 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:12,333 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:38:12,333 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:38:12,333 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:38:12,333 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 2762/2762 [00:09<00:00, 286.46ba/s]\n",
            "2022-02-15 14:38:25,067 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,069 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:38:25,069 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,070 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,070 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,070 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,070 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:38:25,089 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,089 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,090 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,092 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:38:25,092 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,092 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,092 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,092 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,093 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,093 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,093 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,093 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,093 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,094 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:38:25,094 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8837\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 417\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "  5% 21/417 [00:07<02:24,  2.74it/s]2022-02-15 14:38:49,369 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n",
            "  5% 21/417 [00:08<02:32,  2.60it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1087... (failed 1).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/wandb/offline-run-20220215_143838-hfqvj45b\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20220215_143838-hfqvj45b/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shallow FC\n",
        "! kedro run --params BERT_model:shallow_fc,training_type:transformers,device:cuda,dataset:multilingual,model_name:bert-base-multilingual-cased"
      ],
      "metadata": {
        "id": "zxTkcb2LyRQH",
        "outputId": "e1ed5dbc-de92-4db5-f624-1c473de7e233",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:35:39,626 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:35:39,646 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:35:40,220 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:35:43,648 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:43,648 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:35:43,648 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:35:43,689 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:35:43,702 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:35:43,744 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual]) -> [cleaned_dataset]\n",
            "2022-02-15 14:35:43,745 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:43,747 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:35:43,747 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:43,747 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:35:43,747 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:35:43,747 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:35:43,748 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 2762/2762 [00:09<00:00, 281.49ba/s]\n",
            "2022-02-15 14:35:56,708 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,711 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:35:56,711 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,711 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,711 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,712 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,712 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:35:56,729 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,729 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,730 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,731 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:35:56,731 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,731 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,731 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,731 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,732 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,732 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,732 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,732 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,732 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,732 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:35:56,733 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8837\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 417\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "  7% 29/417 [00:10<02:21,  2.73it/s]2022-02-15 14:36:21,986 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n",
            "  7% 29/417 [00:10<02:26,  2.65it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 907... (failed 1).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/wandb/offline-run-20220215_143607-kbhmb6t4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20220215_143607-kbhmb6t4/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMDB dataset"
      ],
      "metadata": {
        "id": "qT6NcnVv3NNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classic"
      ],
      "metadata": {
        "id": "XPJe_b_l3Txw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN\n",
        "! kedro run --params BERT_model:cnn,training_type:classic,device:cuda,dataset:imdb,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "G55dK6z33-nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN\n",
        "! kedro run --params BERT_model:rnn,training_type:classic,device:cuda,dataset:imdb,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "9W1sV8Lm3-dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep FC\n",
        "! kedro run --params BERT_model:deep_fc,training_type:classic,device:cuda,dataset:imdb,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "tM_rJGQb3-bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shallow FC\n",
        "! kedro run --params BERT_model:shallow_fc,training_type:classic,device:cuda,dataset:imdb,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "hbmqETBy1uWh",
        "outputId": "68b6306a-93e1-4a6c-e66c-4802f344ecc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:50:58,732 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:50:58,752 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:50:59,209 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:51:02,306 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:51:02,306 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:51:02,307 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:51:02,347 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:51:02,359 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:51:02,402 - kedro.io.data_catalog - INFO - Loading data from `imdb` (CSVDataSet)...\n",
            "2022-02-15 14:51:02,867 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual,imdb]) -> [cleaned_dataset]\n",
            "2022-02-15 14:51:02,869 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:51:02,871 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:51:02,872 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:51:02,872 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:51:02,872 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:51:02,872 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:51:02,872 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 6258/6258 [02:17<00:00, 45.67ba/s]\n",
            "2022-02-15 14:53:22,301 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,310 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:53:22,310 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,311 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,311 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,311 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,311 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:53:22,345 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,346 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,346 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,348 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:53:22,348 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,349 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,349 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,349 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,349 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,349 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,349 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,349 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,349 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,350 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:53:22,350 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "Epoch 1 / 3:\n",
            "Batch 11/313 |███>................................................................................................| 3.51% complete, loss=0.00, accuracy=02022-02-15 14:53:34,144 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformers"
      ],
      "metadata": {
        "id": "rWqAetv_4JYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN\n",
        "! kedro run --params BERT_model:cnn,training_type:transformers,device:cuda,dataset:imdb,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "y-a3jscr4Nlg",
        "outputId": "1d598f0f-2cd3-427d-d587-aa9980b5ae5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 14:54:58,964 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
            "2022-02-15 14:54:58,988 - kedro.framework.session.session - INFO - ** Kedro project get-started\n",
            "2022-02-15 14:54:59,461 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "/usr/local/lib/python3.7/dist-packages/kedro/io/data_catalog.py:194: DeprecationWarning: The transformer API will be deprecated in Kedro 0.18.0.Please use Dataset Hooks to customise the load and save methods.For more information, please visithttps://kedro.readthedocs.io/en/stable/07_extend_kedro/02_hooks.html\n",
            "  DeprecationWarning,\n",
            "2022-02-15 14:55:02,687 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:55:02,687 - kedro.io.data_catalog - INFO - Loading data from `params:multilingual_task` (MemoryDataSet)...\n",
            "2022-02-15 14:55:02,687 - kedro.io.data_catalog - INFO - Loading data from `davidson` (CSVDataSet)...\n",
            "2022-02-15 14:55:02,728 - kedro.io.data_catalog - INFO - Loading data from `waseem` (CSVDataSet)...\n",
            "2022-02-15 14:55:02,740 - kedro.io.data_catalog - INFO - Loading data from `multilingual` (CSVDataSet)...\n",
            "2022-02-15 14:55:02,783 - kedro.io.data_catalog - INFO - Loading data from `imdb` (CSVDataSet)...\n",
            "2022-02-15 14:55:03,111 - kedro.pipeline.node - INFO - Running node: clean: clean_data([params:dataset,params:multilingual_task,davidson,waseem,multilingual,imdb]) -> [cleaned_dataset]\n",
            "2022-02-15 14:55:03,112 - kedro.io.data_catalog - INFO - Saving data to `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:55:03,115 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks\n",
            "2022-02-15 14:55:03,115 - kedro.io.data_catalog - INFO - Loading data from `cleaned_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:55:03,116 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:55:03,116 - kedro.io.data_catalog - INFO - Loading data from `params:tokenize_batch_size` (MemoryDataSet)...\n",
            "2022-02-15 14:55:03,116 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:55:03,116 - kedro.pipeline.node - INFO - Running node: prepare: prepare_data([cleaned_dataset,params:model_name,params:tokenize_batch_size,params:sentence_max_length]) -> [dataset]\n",
            "100% 6258/6258 [02:17<00:00, 45.48ba/s]\n",
            "2022-02-15 14:57:23,208 - kedro.io.data_catalog - INFO - Saving data to `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,217 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks\n",
            "2022-02-15 14:57:23,218 - kedro.io.data_catalog - INFO - Loading data from `dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,218 - kedro.io.data_catalog - INFO - Loading data from `params:unbalanced` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,218 - kedro.io.data_catalog - INFO - Loading data from `params:train_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,219 - kedro.io.data_catalog - INFO - Loading data from `params:test_size_ratio` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,219 - kedro.pipeline.node - INFO - Running node: split: split_data([dataset,params:unbalanced,params:train_size_ratio,params:test_size_ratio]) -> [train_dataset,eval_dataset,test_dataset]\n",
            "2022-02-15 14:57:23,251 - kedro.io.data_catalog - INFO - Saving data to `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,251 - kedro.io.data_catalog - INFO - Saving data to `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,252 - kedro.io.data_catalog - INFO - Saving data to `test_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,254 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks\n",
            "2022-02-15 14:57:23,254 - kedro.io.data_catalog - INFO - Loading data from `params:BERT_model` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,254 - kedro.io.data_catalog - INFO - Loading data from `params:model_name` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,254 - kedro.io.data_catalog - INFO - Loading data from `params:dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,254 - kedro.io.data_catalog - INFO - Loading data from `params:sentence_max_length` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,255 - kedro.io.data_catalog - INFO - Loading data from `params:learning_rate` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,255 - kedro.io.data_catalog - INFO - Loading data from `params:training_type` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,255 - kedro.io.data_catalog - INFO - Loading data from `params:train_args` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,255 - kedro.io.data_catalog - INFO - Loading data from `params:device` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,255 - kedro.io.data_catalog - INFO - Loading data from `train_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,256 - kedro.io.data_catalog - INFO - Loading data from `eval_dataset` (MemoryDataSet)...\n",
            "2022-02-15 14:57:23,256 - kedro.pipeline.node - INFO - Running node: train: train([params:BERT_model,params:model_name,params:dataset,params:sentence_max_length,params:learning_rate,params:training_type,params:train_args,params:device,train_dataset,eval_dataset]) -> [trained_model]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 20025\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 939\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "  1% 10/939 [00:13<20:02,  1.29s/it]2022-02-15 14:58:18,853 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.\n",
            "\n",
            "Aborted!\n",
            "  1% 10/939 [00:14<22:13,  1.44s/it]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1614... (failed 1).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/Hate-Speech-Detection-in-Social-Media/Irirs_kedro/get-started/wandb/offline-run-20220215_145801-3e3lp59l\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20220215_145801-3e3lp59l/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN\n",
        "! kedro run --params BERT_model:rnn,training_type:transformers,device:cuda,dataset:imdb,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "h2N1Yjhp4ODW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep FC\n",
        "! kedro run --params BERT_model:deep_fc,training_type:transformers,device:cuda,dataset:imdb,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "oAqt2G424N-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shallow FC\n",
        "! kedro run --params BERT_model:shallow_fc,training_type:transformers,device:cuda,dataset:imdb,model_name:bert-base-uncased"
      ],
      "metadata": {
        "id": "bHXYpwyR4N56"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
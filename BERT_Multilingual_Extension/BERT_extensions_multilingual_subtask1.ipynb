{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hafezgh/Hate-Speech-Detection-in-Social-Media/blob/main/BERT_Multilingual_Extension/BERT_extensions_multilingual_subtask1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4ga5LLSSPQN"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqOFKm6QLoua",
        "outputId": "751f95cc-43fb-4bfc-c3a2-e86455ca85a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.1.96)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (1.21.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (3.4.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.0.47)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.8.0rc4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==3.0.0\n",
        "!pip install emoji\n",
        "import gc\n",
        "import os\n",
        "import emoji as emoji\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from transformers import AutoModel\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import copy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3lx2XKTSOn6",
        "outputId": "0d5f5c22-1ec7-46a4-c112-d3dcc18c4c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hasoc-fire-2020'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 35 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/suman101112/hasoc-fire-2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuSosYM7cRvu"
      },
      "source": [
        "# Read and prepare data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FEVTapdDccBw",
        "outputId": "33a971e3-5e03-4f37-eb22-c4632efdb36f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ff125414-b292-4852-b48a-c1c572128b9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.123757e+18</td>\n",
              "      <td>hate wen females hit ah nigga with tht bro ðŸ˜‚ðŸ˜‚,...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_2574</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.123733e+18</td>\n",
              "      <td>RT @airjunebug: When you're from the Bay but y...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_3627</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.123734e+18</td>\n",
              "      <td>RT @DonaldJTrumpJr: Dear Democrats: The Americ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_en_3108</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.126951e+18</td>\n",
              "      <td>RT @SheLoveTimothy: He ainâ€™t on drugs he just ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_3986</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.126864e+18</td>\n",
              "      <td>RT @TavianJordan: Summer â€˜19 Iâ€™m coming for yo...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_en_5152</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff125414-b292-4852-b48a-c1c572128b9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff125414-b292-4852-b48a-c1c572128b9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff125414-b292-4852-b48a-c1c572128b9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       tweet_id  ... language\n",
              "0  1.123757e+18  ...        0\n",
              "1  1.123733e+18  ...        0\n",
              "2  1.123734e+18  ...        0\n",
              "3  1.126951e+18  ...        0\n",
              "4  1.126864e+18  ...        0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data_en = pd.read_excel(\"/content/hasoc-fire-2020/2020/hasoc_2020_en_train_new_a.xlsx\")\n",
        "data_en_test = pd.read_csv(\"/content/hasoc-fire-2020/2020/english_test_1509.csv\")\n",
        "data_en['language'] = 0\n",
        "data_en_test['language'] = 0\n",
        "data_de = pd.read_excel(\"/content/hasoc-fire-2020/2020/hasoc_2020_de_train_new_a.xlsx\")\n",
        "data_de_test = pd.read_csv(\"/content/hasoc-fire-2020/2020/german_test_1509.csv\")\n",
        "data_de['language'] = 1\n",
        "data_de_test['language'] = 1\n",
        "data_hi = pd.read_excel(\"/content/hasoc-fire-2020/2020/hasoc_2020_hi_train_a.xlsx\")\n",
        "data_hi_test = pd.read_csv(\"/content/hasoc-fire-2020/2020/hindi_test_1509.csv\")\n",
        "data_hi['language'] = 2\n",
        "data_hi_test['language'] = 2\n",
        "\n",
        "data = copy.deepcopy(data_en)\n",
        "data = data.append(data_de, ignore_index=True)\n",
        "data = data.append(data_hi, ignore_index=True)\n",
        "data_test = copy.deepcopy(data_en_test)\n",
        "data_test = data_test.append(data_de_test, ignore_index=True)\n",
        "data_test = data_test.append(data_hi_test, ignore_index=True)\n",
        "\n",
        "labels = data[['task1', 'task2', 'language']]\n",
        "le = LabelEncoder()\n",
        "labels['task1'] = le.fit_transform(labels['task1'])\n",
        "le = LabelEncoder()\n",
        "labels['task2'] = le.fit_transform(labels['task2'])\n",
        "\n",
        "labels_test = data_test[['task1', 'task2', 'language']]\n",
        "le = LabelEncoder()\n",
        "labels_test['task1'] = le.fit_transform(labels_test['task1'])\n",
        "le = LabelEncoder()\n",
        "labels_test['task2'] = le.fit_transform(labels_test['task2'])\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NqTc_ZxDnv9G",
        "outputId": "023d91d7-b0e0-49e2-cde5-f8e31257faae"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-48ae3bd0-5509-495d-beb1-7b9a7c8689e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9039</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9040</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9041</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9042</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9043</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9044 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48ae3bd0-5509-495d-beb1-7b9a7c8689e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48ae3bd0-5509-495d-beb1-7b9a7c8689e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48ae3bd0-5509-495d-beb1-7b9a7c8689e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      task1  task2  language\n",
              "0         0      3         0\n",
              "1         0      3         0\n",
              "2         1      1         0\n",
              "3         0      3         0\n",
              "4         1      1         0\n",
              "...     ...    ...       ...\n",
              "9039      1      1         2\n",
              "9040      1      1         2\n",
              "9041      0      0         2\n",
              "9042      0      2         2\n",
              "9043      1      1         2\n",
              "\n",
              "[9044 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y_hEbxWJL0qd"
      },
      "outputs": [],
      "source": [
        "data = data.drop(columns=['tweet_id','task1', 'task2','language','ID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uPjKgBj-dsEW"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(data, labels, train_size=0.85, shuffle=True, random_state=2045)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2ZW8Hv7jk_z9"
      },
      "outputs": [],
      "source": [
        "train_set = X_train['text'].to_list()\n",
        "train_labels1 = y_train['task1'].to_list()\n",
        "train_labels2 = y_train['task2'].to_list()\n",
        "train_langs = y_train['language'].to_list()\n",
        "\n",
        "val_set = X_val['text'].to_list()\n",
        "val_labels1 = y_val['task1'].to_list()\n",
        "val_labels2 = y_val['task2'].to_list()\n",
        "val_langs = y_val['language'].to_list()\n",
        "\n",
        "test_set = data_test['text'].to_list()\n",
        "test_labels1 = labels_test['task1'].to_list()\n",
        "test_labels2 = labels_test['task2'].to_list()\n",
        "test_langs = labels_test['language'].to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJDieo15h1ce"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gO3xhOTncTu0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def pre_process_dataset(values):\n",
        "    new_values = list()\n",
        "    # Emoticons\n",
        "    emoticons = [':-)', ':)', '(:', '(-:', ':))', '((:', ':-D', ':D', 'X-D', 'XD', 'xD', 'xD', '<3', '</3', ':\\*',\n",
        "                 ';-)',\n",
        "                 ';)', ';-D', ';D', '(;', '(-;', ':-(', ':(', '(:', '(-:', ':,(', ':\\'(', ':\"(', ':((', ':D', '=D',\n",
        "                 '=)',\n",
        "                 '(=', '=(', ')=', '=-O', 'O-=', ':o', 'o:', 'O:', 'O:', ':-o', 'o-:', ':P', ':p', ':S', ':s', ':@',\n",
        "                 ':>',\n",
        "                 ':<', '^_^', '^.^', '>.>', 'T_T', 'T-T', '-.-', '*.*', '~.~', ':*', ':-*', 'xP', 'XP', 'XP', 'Xp',\n",
        "                 ':-|',\n",
        "                 ':->', ':-<', '$_$', '8-)', ':-P', ':-p', '=P', '=p', ':*)', '*-*', 'B-)', 'O.o', 'X-(', ')-X']\n",
        "\n",
        "    for value in values:\n",
        "        # Remove dots\n",
        "        text = value.replace(\".\", \"\").lower()\n",
        "        text = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", text)\n",
        "        users = re.findall(\"[@]\\w+\", text)\n",
        "        for user in users:\n",
        "            text = text.replace(user, \"<user>\")\n",
        "        urls = re.findall(r'(https?://[^\\s]+)', text)\n",
        "        if len(urls) != 0:\n",
        "            for url in urls:\n",
        "                text = text.replace(url, \"<url >\")\n",
        "        for emo in text:\n",
        "            if emo in emoji.UNICODE_EMOJI:\n",
        "                text = text.replace(emo, \"<emoticon >\")\n",
        "        for emo in emoticons:\n",
        "            text = text.replace(emo, \"<emoticon >\")\n",
        "        numbers = re.findall('[0-9]+', text)\n",
        "        for number in numbers:\n",
        "            text = text.replace(number, \"<number >\")\n",
        "        text = text.replace('#', \"<hashtag >\")\n",
        "        text = re.sub(r\"([?.!,Â¿])\", r\" \", text)\n",
        "        text = \"\".join(l for l in text if l not in string.punctuation)\n",
        "        text = re.sub(r'[\" \"]+', \" \", text)\n",
        "        new_values.append(text)\n",
        "    return new_values\n",
        "\n",
        "\n",
        "def data_process(data, labels):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "    for sentence in data:\n",
        "        bert_inp = bert_tokenizer.__call__(sentence, max_length=64,\n",
        "                                           padding='max_length', pad_to_max_length=True,\n",
        "                                           truncation=True, return_token_type_ids=False)\n",
        "\n",
        "        input_ids.append(bert_inp['input_ids'])\n",
        "        attention_masks.append(bert_inp['attention_mask'])\n",
        "    #del bert_tokenizer\n",
        "    #gc.collect()\n",
        "    #torch.cuda.empty_cache()\n",
        "    input_ids = np.asarray(input_ids)\n",
        "    attention_masks = np.array(attention_masks)\n",
        "    labels = np.array(labels)\n",
        "    return input_ids, attention_masks, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32c0j8mp3Jzz"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CUcU4tEVLvun"
      },
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert, n_classes, mode='cnn'):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "        self.n_classes = n_classes\n",
        "        self.mode = mode\n",
        "\n",
        "        if mode == 'cnn':\n",
        "            # CNN\n",
        "            self.conv = nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(3, 768), padding='valid')\n",
        "            self.relu = nn.ReLU()\n",
        "            # change the kernel size either to (3,1), e.g. 1D max pooling\n",
        "            # or remove it altogether\n",
        "            self.pool = nn.MaxPool2d(kernel_size=(3, 1), stride=1)\n",
        "            self.dropout = nn.Dropout(0.1)\n",
        "            # be careful here, this needs to be changed according to your max pooling\n",
        "            # without pooling: 443, with 3x1 pooling: 416\n",
        "            # Size after conv = BERT max length - 3 + 1\n",
        "            # Size after pool = Size after conv - 3 + 1\n",
        "            # (BERT max length - 3 + 1) - 3 + 1 == BERT max length - 4\n",
        "            # (kernel_size * (BERT max length - 4), num. classes)\n",
        "\n",
        "            # IN THIS CASE MAX LENGTH IS SET TO 64\n",
        "            # FC\n",
        "            self.fc = nn.Linear(13 * (64 - 4), self.n_classes).to(device)\n",
        "            self.flat = nn.Flatten()\n",
        "            \n",
        "        elif mode == 'rnn':\n",
        "            ### RNN\n",
        "            self.lstm = nn.LSTM(768, 256, batch_first=True, bidirectional=True)\n",
        "            ## FC\n",
        "            self.fc = nn.Linear(256*2, self.n_classes)\n",
        "        elif mode == 'shallow_fc':\n",
        "            self.fc = nn.Linear(768, self.n_classes)\n",
        "        elif mode == 'deep_fc':\n",
        "            self.leaky_relu = nn.LeakyReLU(0.01)\n",
        "            self.fc1 = nn.Linear(768, 768)\n",
        "            self.dropout = nn.Dropout(0.1)\n",
        "            self.fc2 = nn.Linear(768, 768)\n",
        "            self.dropout = nn.Dropout(0.1)\n",
        "            self.fc3 = nn.Linear(768, self.n_classes)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Unsupported extension!\")\n",
        "\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        sequence_output, _, all_layers = self.bert(sent_id, attention_mask=mask, output_hidden_states=True)\n",
        "        if self.mode == 'cnn':\n",
        "            x = torch.transpose(torch.cat(tuple([t.unsqueeze(0) for t in all_layers]), 0), 0, 1)\n",
        "            x = self.pool(self.dropout(self.relu(self.conv(self.dropout(x)))))\n",
        "            x = self.fc(self.dropout(self.flat(self.dropout(x))))\n",
        "        elif self.mode == 'rnn':\n",
        "            lstm_output, (h,c) = self.lstm(sequence_output)\n",
        "            hidden = torch.cat((lstm_output[:,-1, :256],lstm_output[:,0, 256:]),dim=-1)\n",
        "            x  = self.fc(hidden.view(-1,256*2))\n",
        "        elif self.mode == 'shallow_fc':\n",
        "            x = self.fc(sequence_output[:,0,:])\n",
        "        elif self.mode == 'deep_fc':\n",
        "            x = self.fc1(sequence_output[:,0,:])\n",
        "            x = self.leaky_relu(x)\n",
        "            x = self.fc2(x)\n",
        "            x = self.leaky_relu(x)\n",
        "            x = self.fc3(x)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Unsupported extension!\")\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        del all_layers\n",
        "        c = self.softmax(x)\n",
        "        return c\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v8P9TN4So5Y"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c1fcW3fcia33"
      },
      "outputs": [],
      "source": [
        "\n",
        "# function to train the model\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    total = len(train_dataloader)\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "        step = i+1\n",
        "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
        "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
        "        filledLength = int(100 * step // total)\n",
        "        bar = 'â–ˆ' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
        "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        #sent_id = torch.tensor(sent_id).to(device).long()\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        #preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        # append the model predictions\n",
        "        #total_preds.append(preds)\n",
        "        total_preds.append(preds.detach().cpu().numpy())\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / (len(train_dataloader)*batch_size)\n",
        "\n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    # returns the loss and predictions\n",
        "    return avg_loss, total_preds\n",
        "\n",
        "\n",
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "    print(\"\\n\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    total = len(val_dataloader)\n",
        "    for i, batch in enumerate(val_dataloader):\n",
        "        \n",
        "        step = i+1\n",
        "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
        "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
        "        filledLength = int(100 * step // total)\n",
        "        bar = 'â–ˆ' * filledLength + '>' * (filledLength < 100) + '.' * (99 - filledLength)\n",
        "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds, labels)\n",
        "\n",
        "            total_loss += float(loss.item())\n",
        "            #preds = preds.detach().cpu().numpy()\n",
        "\n",
        "            #total_preds.append(preds)\n",
        "            total_preds.append(preds.detach().cpu().numpy())\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / (len(val_dataloader)*batch_size)\n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "0Y3L2lH1mROW"
      },
      "outputs": [],
      "source": [
        "### Extension mode\n",
        "MODE = 'rnn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "xe5O3NoS3cWp"
      },
      "outputs": [],
      "source": [
        "pre_pro_train_data = pre_process_dataset(train_set)\n",
        "pre_pro_val_data = pre_process_dataset(val_set)\n",
        "pre_pro_test_data = pre_process_dataset(test_set)\n",
        "\n",
        "train_input_ids, train_attention_masks, train_labels = data_process(pre_pro_train_data,train_labels1)\n",
        "val_input_ids, val_attention_masks, val_labels = data_process(pre_pro_val_data,val_labels1)\n",
        "test_input_ids, test_attention_masks, test_labels = data_process(pre_pro_test_data,test_labels1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH3HDzr9WDgY",
        "outputId": "3fb33b94-fec5-4ff2-b842-de56edbe7806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Specify the GPU\n",
        "# Setting up the device for GPU usage\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "train_count = len(train_labels)\n",
        "test_count = len(test_labels)\n",
        "val_count = len(val_labels)\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~ Import BERT Model and BERT Tokenizer ~~~~~~~~~~~~~~~~~~~~~#\n",
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-multilingual-cased')\n",
        "# bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "# Load the BERT tokenizer\n",
        "#tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "bUtglOzvL6bU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Tokenization ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "# for train set\n",
        "train_seq = torch.tensor(train_input_ids.tolist())\n",
        "train_mask = torch.tensor(train_attention_masks.tolist())\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(val_input_ids.tolist())\n",
        "val_mask = torch.tensor(val_attention_masks.tolist())\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(test_input_ids.tolist())\n",
        "test_mask = torch.tensor(test_attention_masks.tolist())\n",
        "test_y = torch.tensor(test_labels.tolist())\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Create DataLoaders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Freeze BERT Parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert, n_classes=2, mode=MODE)\n",
        "# push the model to GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "#from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# compute the class weights\n",
        "#class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "#print(class_wts)\n",
        "\n",
        "# convert class weights to tensor\n",
        "#weights = torch.tensor(class_wts, dtype=torch.float)\n",
        "#weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "#cross_entropy = nn.NLLLoss(weight=weights)\n",
        "cross_entropy = nn.NLLLoss()\n",
        "\n",
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "#train_losses = []\n",
        "#valid_losses = []\n",
        "\n",
        "#if os.path.isfile(\"/content/drive/MyDrive/saved_weights.pth\") == False:\n",
        "#if os.path.isfile(\"saved_weights.pth\") == False:\n",
        "    # number of training epochs\n",
        "epochs = 3\n",
        "current = 1\n",
        "# for each epoch\n",
        "while current <= epochs:\n",
        "\n",
        "    print(f'\\nEpoch {current} / {epochs}:')\n",
        "\n",
        "    # train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        #torch.save(model.state_dict(), 'saved_weights.pth')\n",
        "\n",
        "    # append training and validation loss\n",
        "    #train_losses.append(train_loss)\n",
        "    #valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\n\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    current = current + 1\n",
        "#else:\n",
        "    #print(\"Got weights!\")\n",
        "    # load weights of best model\n",
        "    #model.load_state_dict(torch.load(\"saved_weights.pth\"))\n",
        "    #model.load_state_dict(torch.load(\"/content/drive/MyDrive/saved_weights.pth\"), strict=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIyWdkPISOp8"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmwow4GrZlfA"
      },
      "outputs": [],
      "source": [
        "# get predictions for test data\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for i in range(len(test_seq)):\n",
        "        pred = model(test_seq[i].unsqueeze(0).to(device), test_mask[i].unsqueeze(0).to(device)).detach().cpu().numpy()\n",
        "        preds.append(pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Performance:\")\n",
        "# model's performance\n",
        "preds = np.argmax(preds, axis=1)\n",
        "print('Classification Report (Overall)')\n",
        "print(classification_report(test_y, preds))\n",
        "\n",
        "print(\"Accuracy: \" + str(accuracy_score(test_y, preds)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4-GJOqHkabo",
        "outputId": "cc7b4241-820c-46c5-f072-e5eba571c775"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance:\n",
            "Classification Report (Overall)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.66      0.71       754\n",
            "           1       0.81      0.88      0.84      1249\n",
            "\n",
            "    accuracy                           0.80      2003\n",
            "   macro avg       0.79      0.77      0.78      2003\n",
            "weighted avg       0.80      0.80      0.79      2003\n",
            "\n",
            "Accuracy: 0.7973040439340988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(test_y, preds, labels=[0,1,])\n",
        "disp_cm = ConfusionMatrixDisplay(cm, display_labels = ['HOF', 'NOT'])\n",
        "disp_cm.plot(cmap='Blues')"
      ],
      "metadata": {
        "id": "mhbXarh9wflI",
        "outputId": "2a4fec5e-e163-46f4-f323-fc450bef73e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f21a529db90>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEGCAYAAADhb8drAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdcElEQVR4nO3debxVZd338c/3gIDIcJhEAgccckxJUVGMNMu5sDKH0HAotES7NSuHuzDrcbrzVkvTB4eCcp6SnMgcHpwTFBXFgiQFQpknxQH9PX/s6+DmwOGsfTh777P3+b59rddZ61rTb58tv3Nd61rrWooIzMwsm5pyB2BmVkmcNM3MCuCkaWZWACdNM7MCOGmamRWgbbkDaA6da7tHzz79yh2GFaBz+w3KHYIV6JWXXpgfEb3W5xhtumwesXJFpm1jxbzxEXHQ+pyvGKoiafbs04/zx95X7jCsAPtt1bvcIViBNu/R4c31PUasXEH7bY/MtO37k6/uub7nK4aqSJpmVikEquyrgk6aZlY6AmralDuK9eKkaWalJZU7gvXipGlmJeTmuZlZYVzTNDPLSLimaWaWnVzTNDMriHvPzcyyckeQmVl2ws1zM7OCuKZpZpaVm+dmZtkJaOOOIDOz7HxN08wsKzfPzcwK45qmmVkBXNM0M8tIlf8YZWWnfDOrPDVtsk2NkHSjpLmSpuSVdZf0sKRp6We3VC5Jv5E0XdLLknbN22d42n6apOGNht/Ej21m1gSpIyjL1Lg/APVfvHY28EhEbAM8kpYBDga2SdMI4BrIJVlgFLAnsAcwqi7RNsRJ08xKq66J3tjUiIiYACysVzwUGJPmxwCH55WPjZxngVpJfYADgYcjYmFELAIeZs1EvBpf0zSz0ilsPM2ekibmLY+OiNGN7NM7Iuak+beButee9gVm5m03K5U1VN4gJ00zK6GC7tOcHxEDm3qmiAhJ0dT9G+LmuZmVVjN1BDXgndTsJv2cm8pnA5vmbdcvlTVU3nD4TY3MzKxJmumaZgPGAXU94MOBe/PKv5N60QcBS1IzfjxwgKRuqQPogFTWIDfPzax01HyPUUq6BdiX3LXPWeR6wS8Gbpd0EvAmcGTa/AHgEGA68B5wAkBELJT0S+D5tN0FEVG/c2k1TppmVlrNdHN7RBzTwKr917JtAKc2cJwbgRuzntdJ08xKShX+RJCTppmVTO5tF06aZmbZSKjGSdPMLDPXNM3MCuCkaWZWACdNM7OslKYK5qRpZiUj5JqmmVkhamoq++ltJ00zKynXNM3MsvI1TTOzwrimaWaWkTuCzMwK5McozcyykpvnZmYFcdI0MyuAk6aZWUbuCDIzK1Rl50wnTTMrIfkxSjOzgrh5bmZWiMrOmU6a5XbuOdfSoX07ampqqGkjzj1vOO++u4LrRo9jwYIl9OjRle+NGMpGG3UgIrj9tkeY8sobtGu3AcOPP5jNNt+k3B+hVZkzdxE/ufgWFixajgRHHjqI4d8cwm/HjOf2+5+le20nAM486RC+uOf2q/b7zzuLOPTESxk5/ABOOnK/coXfIrim2QBJyyOiU97y8cDAiBiZlkcAZ6bVS4EzI+LJtO5xoA+wIq3/VUTcWaxYy+3MHx1Np84dVy0/9OBzbLfd5hx08CAeevBZxj/0LN/45r5MmfIGc99ZxAW/+h4zZszh5pse5uxzjytj5K1PmzZtOPuUr7HjZ/ux/L33+eYplzN4t88CcPwRQxpMiBdfM44v7LFdKUNtkaTK7z0vyxVZSYcBJwP7RMR2wCnAzZLyq03DImJAmqo2Ya7Nyy9NY6+9dgJgr7124qXJ03Llk6czaK8dkcSWW36GFSveZ8ni5eUMtdXZuEcXdvxsPwA6dezAlpv35p35S9a5z9+efIW+fbqzzRZuFcCnibOxqaUqVzfWT4EfR8R8gIh4ARgDnFqmeMpGiCuvuJ0LfzWGJyZMBmDp0vfompp5XbpuxNKl7wGwePEyunXrsmrf2m6dWbx4WemDNgBmvb2QqdNns8v2mwNw05+f4qvf/TXn/M+tLFmW+87eXfEB1936GCO/c0A5Q21RVKNMU0tVzGuaG0qanLfcHRiX5ncEJtXbfiIwPG/5Jkl1zfP9I2JB/sapeT8CoMcmfZst6FI76yffplu3zixd+i5XXnE7m2zSY7X1ub+6ZQrOGvTuig84/fwxnPuDoXTaqAPHfHVvfnDsV5Dgyt8/xMXXjuOiHx/NVWPGM/yIIWy0Yftyh9xitORaZBbFTJorImJA3ULdNc0C9h8WERMbWhkRo4HRAP233zmaGmS5devWGYAuXTZiwIBtmPHvOXTp0pEli5fTtbYTSxYvp3O63llb25lFi5au2nfxomXU1nYuS9yt2UcrP+b08//AV/fflQO+sDMAPbt/+j1869BBnHLeDQC8NPUtxk94mV+Pvo+ly1dQUyPat9uAYw/fpyyxl50H7Giy14DdgEfzynYDXi1POOXxwQcfEhF06NCeDz74kKmv/ZtDD9ubnXfZmmeemcJBBw/imWemsPMu2wCw8y5b8/hjLzBw9+2ZMWMOHTZsv6oZb6UREZz369vYcrPenPCtL64qn7tgKRv3yF06+duTr6y6fnnzlSNXbfPbMePpuGG71pswSQO3V3bOLFvSvBS4RNJBEbFA0gDgeGDPMsVTFkuXvse119wDwCcff8Lue+zAjjttyeZb9OG60ffy1FMv06N7V7538tcA2OlzWzJlyhv87LzraNeuLcOPP7ic4bdKk6bM4N6HJ/HZ/n0YOuIyIHd70X2Pvsjr/5oNiL6bdOOCM75V3kBbrJbdyZNFWZJmRIyT1Bd4WlIAy4BjI2JOOeIpl169avnZz09Yo7xTpw0548yj1yiXxDHf/kopQrMGDPzclvzjkcvWKM+/J7Mhpw0/sBghVZyaFtzJk0XRkmb+PZpp+Q/AH/KWrwGuaWDffYsVl5mVkdw8NzPLTLimaWZWENc0zcwK4I4gM7OsfE3TzCw7oYofhLiyozeziiNlmxo/js6Q9KqkKZJukdRBUn9Jz0maLuk2Se3Stu3T8vS0foumxu+kaWYl1RyjHKX7vE8nN9zkTkAb4GjgEuDyiNgaWASclHY5CViUyi9P2zWJk6aZlU7GWmbG655tyQ0M1BboCMwBvgTUDSU5Bjg8zQ9Ny6T1+6uJPVJOmmZWMrlnzzPXNHtKmpg3jag7TkTMBn4NvEUuWS4hN3La4ohYmTabBdQNgdYXmJn2XZm2X31IsYzcEWRmJVVA/W5+RKx1ZDRJ3cjVHvsDi4E7gIOaI77GOGmaWUk10xNBXwZmRMQ8AEl3A4OBWkltU22yHzA7bT8b2BSYlZrzXYEFax62cW6em1npqNled/EWMEhSx3Rtcn9yQ04+BhyRthkO3Jvmx/HpIOdHAI9GRJPG4XVN08xKprnG04yI5yTdCbwArAReJDco+f3ArZJ+lcpuSLvcAPxR0nRgIbme9iZx0jSzEmq+8TQjYhQwql7xG8Aea9n2faBZBjl10jSzkvJjlGZmWclDw5mZZVZ3n2Ylc9I0s5Jy0jQzK0CF50wnTTMrLdc0zcyy8iDEZmbZ5QYhruys6aRpZiVVU+FVTSdNMyupCs+ZTppmVjqSO4LMzApS4Zc0G06akn4LNDh0UkScXpSIzKyqVXNH0MSSRWFmrYLI9aBXsgaTZkSMyV+W1DEi3it+SGZWzSq8otn4yO2S9pL0GvB6Wt5F0u+KHpmZVZ+Mo7a35M6iLK+7uAI4kPQ+jYh4CRhSzKDMrHo14yt8yyJT73lEzKyX+T8uTjhmVs1E67i5faakvYGQtAHwQ2BqccMys2pV6b3nWZrnpwCnknvZ+n+AAWnZzKwgWZvmLbky2mhNMyLmA8NKEIuZtQKV3jzP0nu+paS/SJonaa6keyVtWYrgzKz6KOPUUmVpnt8M3A70AT4D3AHcUsygzKx6tYZbjjpGxB8jYmWa/gR0KHZgZlZ9cr3n2aaWal3PnndPsw9KOhu4ldyz6EcBD5QgNjOrNqruQYgnkUuSdZ/w5Lx1AZxTrKDMrHq15KZ3Fut69rx/KQMxs+pX1zyvZJmeCJK0E7ADedcyI2JssYIys+pVtTXNOpJGAfuSS5oPAAcDTwJOmmZWsMpOmdl6z48A9gfejogTgF2ArkWNysyqkgRtapRpaqmyNM9XRMQnklZK6gLMBTYtclxmVqWqvnkOTJRUC1xHrkd9OfBMUaMys6pV4Tkz07PnP0iz10p6COgSES8XNywzq0ZCFf/s+bpubt91Xesi4oXihGRmVauFj2CUxbpqmpetY10AX2rmWJqse8d2HPX5zcodhhWg2+4jyx2ClUnVXtOMiP1KGYiZVT8Bbao1aZqZFUMLvpsokyz3aZqZNZvmGuVIUq2kOyW9LmlqenNud0kPS5qWfnZL20rSbyRNl/TyuvpsGo2/qTuamRUq9yqLZhtP80rgoYjYjtxDN1OBs4FHImIb4JG0DLknGbdJ0wjgmqZ+hiwjt0vSsZJ+npY3k7RHU09oZq1bc9Q0JXUl9yrxGwAi4sOIWAwMBcakzcYAh6f5ocDYyHkWqJXUp0nxZ9jmd8BewDFpeRlwdVNOZmZWwIvVekqamDeNyDtMf2Ae8HtJL0q6XtJGQO+ImJO2eRvoneb7AjPz9p+VygqWpSNoz4jYVdKLABGxSFK7ppzMzFo3AW2z957Pj4iBDaxrC+wKnBYRz0m6kk+b4gBEREiKJgfbgCw1zY8ktSF3byaSegGfNHcgZtY6NNMrfGcBsyLiubR8J7kk+k5dszv9nJvWz2b1MTP6pbKCZUmavwHuATaW9H/IDQt3YVNOZmatm5R7jDLLtC4R8TYwU9K2qWh/4DVgHDA8lQ0H7k3z44DvpD6aQcCSvGZ8QbI8e36TpEkpKAGHR8TUppzMzKwZ720/DbgpXS58AziBXEXwdkknAW8CR6ZtHwAOAaYD76VtmyTLIMSbpZP8Jb8sIt5q6knNrPVqrpvbI2IysLZrnvuvZdsATm2O82bpCLqfT1+w1oFcr9U/gB2bIwAzaz0ELXqA4SyyNM8/l7+c7qT/QQObm5k1rIW/0zyLgp89j4gXJO1ZjGDMrPqpwt8SlOWa5pl5izXkuvX/U7SIzKxqtZZX+HbOm19J7hrnXcUJx8yqXVUnzXRTe+eIOKtE8ZhZlavaQYgltY2IlZIGlzIgM6teuVf4ljuK9bOumubfyV2/nCxpHHAH8G7dyoi4u8ixmVkVqtoXq+XpACwg906guvs1A3DSNLOCVHtH0Map53wKnybLOs0+coiZtQ4VXtFcZ9JsA3SCtd5U5aRpZk0gaqr4Ps05EXFBySIxs6onqrumWeEfzcxaHEHbCr+oua6kucZIIWZm66Oqa5oRsbCUgZhZ69AabjkyM2s2FZ4znTTNrHREtnfstGROmmZWOnLz3Mwss9wTQU6aZmaZVXbKdNI0sxKr8Iqmk6aZlZKqdzxNM7Pm5t5zM7MCuSPIzCwrVfHrLszMmpub52ZmBXJN08ysAJWdMp00zayEBLRxTdPMLLsKz5lOmmZWSkIV3kB30jSzknJN08wso9wtR5WdNZ00zax05JqmmVlB/BilmVlGuUGIyx3F+nHSNLOSqvTe80p/DNTMKoyUbcp2LLWR9KKk+9Jyf0nPSZou6TZJ7VJ5+7Q8Pa3foqnxu6ZZRiMv+BPjn5xCz26deea28wC4ePT9jP3z0/So7QTAz079GgcM3pHHnpvKL64ax4cfraTdBm254PTDGbL7tuUMv9X47c+GceA+OzF/0TL2PvpCAGq7dOTGC09ksz7deWvOQk445waWLFtB184bctXPjqV/v568/+FHnPbLm5j6rzlsvfnG3HjhiauOuflnenDR6Pu59pbHy/SpyqeZa5o/BKYCXdLyJcDlEXGrpGuBk4Br0s9FEbG1pKPTdkc15YRFq2lKCkmX5S2fJen8vOURkl5P098l7ZPK75E0Of1FWJLmJ0vau1ixlssxhw3izt+cukb594/ZjyduPocnbj6HAwbvCECP2k7c8r8n8/St5/G7UcdxyqixpQ631brlvmc54vSrVys7Y/hXmPD8Pxj4zQuY8Pw/OGP4AQD86IQDeeWfs9jn2xfx/VF/5KIfHQHA9DfnMmTYxQwZdjH7HncJKz74iPsfe6nkn6Xc6q5pZpkaPZbUDzgUuD4tC/gScGfaZAxweJofmpZJ6/dXE0cOKWbz/APgG5J61l8h6TDgZGCfiNgOOAW4WdImEfH1iBgAfBd4IiIGpOnpIsZaFoN33ZpuXTpm2nbnbTelT69aALbfqg8rPviIDz78qJjhWfL0i/9i0dL3Vis7+Is7c8t9zwFwy33Pcci+OwOwbf9NeGLiPwGY9uY7bNanO726d15t3y/uvi3/njWPmW8vKkH0LYxETcYJ6ClpYt40ot7RrgB+AnySlnsAiyNiZVqeBfRN832BmQBp/ZK0fcGKmTRXAqOBM9ay7qfAjyNiPkBEvEDur8Ca1a5W6Lo7JjD4mAsZecGfWFzvHyvAuEcns8u2m9K+3QZliM4ANu7emXcWLAXgnQVL2TglxinTZnPYfrsAsOsOm7PpJt35zMa1q+37jQN2467xk0obcAuijBMwPyIG5k2jVx0jV/GaGxEl/0UWuyPoamCYpK71yncE6n/Yiak8k9S8nyhp4rz589YzzJbjxG9+gRfvOZ8nbjqb3j278N9X3L3a+qn/msP5v72Xy889ukwR2tpE5H5eMeZhunbuyISbzmbEUV/k5X/O4uNPPlm13QZt23DwkM/x50deLFOk5VX33vOMNc11GQx8TdK/gVvJNcuvBGol1fXV9ANmp/nZwKYAaX1XYEFTPkNRk2ZELAXGAqcX4dij6/4C9erZq7kPXzYb9+hCmzY11NTUMPzwwUx69c1V62a/s4jjfjKaa35xHP37Vc9nrkRzFy6jd49c30PvHl2Yt2gZAMvefZ+RF/yJIcMu5pRRY+lZ24k3Z3/6b/PLe+/AS6/PZN7CZWWJuyUooKbZoIg4JyL6RcQWwNHAoxExDHgMOCJtNhy4N82PS8uk9Y9G1P2pK0wpbjm6glzP1UZ5Za8Bu9Xbbjfg1RLE06K9PX/Jqvn7Hn+J7bfqA8CSZe9x1BnXMurUoQzaZatyhWfJQxNe4ZjD9gTgmMP25MH/9zIAXTptyAZt2wDwncP35ukXp7Ps3fdX7XfEgQO566+tt2kONE/WbNhPgTMlTSd3zfKGVH4D0COVnwmc3dQTFP2Wo4hYKOl2conzxlR8KXCJpIMiYoGkAcDxwJ7FjqclOem83/PUpGksWLycHQ/9b84ecQhPTprGK/+chSQ269Ody889BoDrbp/AjJnzuPT6B7n0+gcBuPuqkWt0Mljzu/5XxzN4t23oUduJKff9kotHP8DlYx7m9xedyLFf24uZby/khHNy/2tv238TfjfqOILg9TfmcNovb1p1nI4d2rHvHttxxoW3lOujtAjN/RhlRDwOPJ7m3wD2WMs27wPfao7zqYk11MYPLC2PiE5pvjcwA7g0Is5PZd8H/gsIYBnwo4iYkLf/vsBZEXFYY+fabbeB8dRzE5v9M1jxdNt9ZLlDsAK9P/nqSRExcH2Osf3nPh9j730807Z7bFW73ucrhqLVNOsSZpp/B+hYb/015G46bWj/x0l/PcysilT2U5R+IsjMSid3ubKys6aTppmVjsfTNDMrTIXnTCdNMysl0cRHvlsMJ00zK6kKz5lOmmZWOut333rL4KRpZqVV4VnTSdPMSsq3HJmZFcDXNM3MsvJ9mmZmhXHz3MwsI+GapplZQSo8ZzppmlmJVXjWdNI0s5Jq7kGIS81J08xKqrJTppOmmZVahWdNJ00zKxkPQmxmVgjf3G5mVpgKz5lOmmZWSh6E2MysIBWeM500zax0PAixmVmhKjxrOmmaWUn5liMzswL4mqaZWVaCGidNM7NCVHbWdNI0s5LxIMRmZgWq8JzppGlmpeWapplZAfwYpZlZASo7ZTppmlkJyUPDmZkVptKfCKopdwBm1soo47SuQ0ibSnpM0muSXpX0w1TeXdLDkqaln91SuST9RtJ0SS9L2rWp4TtpmllJNUPOBFgJ/CgidgAGAadK2gE4G3gkIrYBHknLAAcD26RpBHBNU+N30jSzEhI1yjatS0TMiYgX0vwyYCrQFxgKjEmbjQEOT/NDgbGR8yxQK6lPUz6Br2maWckU+ERQT0kT85ZHR8ToNY4pbQF8HngO6B0Rc9Kqt4Heab4vMDNvt1mpbA4FctI0s5ZqfkQMXNcGkjoBdwH/FRFL8+8BjYiQFM0dlJvnZlZSdbcdNTY1fhxtQC5h3hQRd6fid+qa3enn3FQ+G9g0b/d+qaxgTppmVlLK+N86j5GrUt4ATI2I/81bNQ4YnuaHA/fmlX8n9aIPApbkNeML4ua5mZVO893cPhg4DnhF0uRUdi5wMXC7pJOAN4Ej07oHgEOA6cB7wAlNPbGTppmVTHMNDRcRT9LwnUn7r2X7AE5d/zM7aZpZiVX6E0FOmmZWUn723MysABWeM500zazEKjxrOmmaWckIGn1EsqVTrlOpskmaR+72gmrUE5hf7iCsINX6nW0eEb3W5wCSHiL3+8lifkQctD7nK4aqSJrVTNLExh4ls5bF31l18xNBZmYFcNI0MyuAk2bLt8ZQWNbi+TurYr6maWZWANc0zcwK4KRpZlYAJ80ykbS83vLxkq7KWx4h6fU0/V3SPnnrHpf0D0mT03REKWNvrSSFpMvyls+SdH7e8lq/M0n3pO9puqQled/b3mX4GLae/ERQCyTpMOBkYJ+ImJ9eN/pnSXtExNtps2ERMbHho1gRfAB8Q9JFEbHazeuNfGdfT9vsC5wVEYeVOnBrPq5ptkw/BX5c9w8zvXVvDM00HqA12UpyPeNnrGWdv7NWwkmzfDbMa6ZNBi7IW7cjMKne9hNTeZ2b8vbvUexgbZWrgWGSutYrz/KdWRVw87x8VkTEgLoFSccDhTx65+Z5GaQ3Ho4FTgdWlDseKz3XNFum14Dd6pXtBrxahlhsTVcAJwEb5ZX5O2slnDRbpkuBS+qa3ZIGAMcDvytnUJYTEQuB28klzjr+zloJN89boIgYJ6kv8HR62f0y4NimvnLUiuIyYGTdgr+z1sOPUZqZFcDNczOzAjhpmpkVwEnTzKwATppmZgVw0jQzK4CTZish6eP0yOUUSXdI6rgex/pD3chKkq6XtMM6tt23KaP5SPq3pDXeWthQeb1tlq9r/Vq2P1/SWYXGaK2Tk2brsSIiBkTETsCHwCn5KyU16Z7diPhuRLy2jk32BTwEmlUNJ83W6Qlg61QLfELSOOA1SW0k/Y+k5yW9LOlkAOVclcbw/Buwcd2B0tieA9P8QZJekPSSpEckbUEuOZ+RarlfkNRL0l3pHM9LGpz27SHpr5JelXQ9oMY+hKQ/S5qU9hlRb93lqfwRSb1S2VaSHkr7PCFpu+b4ZVrr4ieCWplUozwYeCgV7QrsFBEzUuJZEhG7S2oPPCXpr8DngW2BHYDe5J6zvrHecXsB1wFD0rG6R8RCSdcCyyPi12m7m4HLI+JJSZsB44HtgVHAkxFxgaRDWf0RxYacmM6xIfC8pLsiYgG5Z8InRsQZkn6ejj2S3LBup0TENEl7knvE8UtN+DVaK+ak2XpsmIagg1xN8wZyzea/R8SMVH4AsHPeSPBdgW2AIcAtEfEx8B9Jj67l+IOACXXHSs9nr82XgR2kVRXJLpI6pXN8I+17v6RFGT7T6ZK+nuY3TbEuAD4BbkvlfwLuTufYG7gj79ztM5zDbDVOmq3HakPRAaTk8W5+EXBaRIyvt90hzRhHDTAoIt5fSyyZpVHQvwzsFRHvSXoc6NDA5pHOu7j+78CsUL6mafnGA9+XtAGApM9K2giYAByVrnn2AfZby77PAkMk9U/7dk/ly4DOedv9FTitbiGNBkQ6x7dT2cFAt0Zi7QosSglzO3I13To1QF1t+dvkmv1LgRmSvpXOIUm7NHIOszU4aVq+68ldr3xB0hTg/5JrjdwDTEvrxgLP1N8xIuYBI8g1hV/i0+bxX4Cv13UEkRu8d2DqaHqNT3vxf0Eu6b5Krpn+ViOxPgS0lTQVuJhc0q7zLrBH+gxf4tNR8YcBJ6X4XgWGZvidmK3GoxyZmRXANU0zswI4aZqZFcBJ08ysAE6aZmYFcNI0MyuAk6aZWQGcNM3MCvD/AQu5wvM1hDFXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6cJkkC_SQQN"
      },
      "source": [
        "# Post-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "kL7ASGELSR1v"
      },
      "outputs": [],
      "source": [
        "### Analyze the results by language\n",
        "# HOF: 0, NOT: 1\n",
        "# Languages, EN: 0, DE: 1, HI: 2\n",
        "\n",
        "test_labels1 = np.array(test_labels1)\n",
        "en_actual = []\n",
        "en_pred = []\n",
        "hi_actual = []\n",
        "hi_pred = []\n",
        "de_actual = []\n",
        "de_pred = []\n",
        "for i in range(len(test_labels)):\n",
        "    if data_test['language'][i] == 0:\n",
        "        en_actual.append(test_labels1[i])\n",
        "        en_pred.append(preds[i])\n",
        "    if data_test['language'][i] == 1:\n",
        "        de_actual.append(test_labels1[i])\n",
        "        de_pred.append(preds[i])\n",
        "    if data_test['language'][i] == 2:\n",
        "        hi_actual.append(test_labels1[i])\n",
        "        hi_pred.append(preds[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# en\n",
        "print('Classification Report (English)')\n",
        "print(classification_report(en_actual, en_pred))\n",
        "print(\"Accuracy: \" + str(accuracy_score(en_actual, en_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r5-RKYRoEwY",
        "outputId": "32fa2a56-3a27-4796-8619-adbe3b18f7df"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (English)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       423\n",
            "           1       0.88      0.83      0.85       391\n",
            "\n",
            "    accuracy                           0.86       814\n",
            "   macro avg       0.87      0.86      0.86       814\n",
            "weighted avg       0.87      0.86      0.86       814\n",
            "\n",
            "Accuracy: 0.8648648648648649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# de\n",
        "print('Classification Report (German)')\n",
        "print(classification_report(de_actual, de_pred))\n",
        "print(\"Accuracy: \" + str(accuracy_score(de_actual, de_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjKbmdowpm1m",
        "outputId": "65f00156-8a1a-4108-89c6-f51d75d8d492"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (German)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.70      0.68       134\n",
            "           1       0.90      0.88      0.89       392\n",
            "\n",
            "    accuracy                           0.83       526\n",
            "   macro avg       0.78      0.79      0.78       526\n",
            "weighted avg       0.84      0.83      0.83       526\n",
            "\n",
            "Accuracy: 0.8326996197718631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hi\n",
        "print('Classification Report (Hindi)')\n",
        "print(classification_report(hi_actual, hi_pred))\n",
        "print(\"Accuracy: \" + str(accuracy_score(hi_actual, hi_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vilM1fepnuo",
        "outputId": "c812a750-dfd3-475e-e167-1357fc72b451"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Hindi)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.13      0.19       197\n",
            "           1       0.71      0.92      0.81       466\n",
            "\n",
            "    accuracy                           0.69       663\n",
            "   macro avg       0.56      0.52      0.50       663\n",
            "weighted avg       0.62      0.69      0.62       663\n",
            "\n",
            "Accuracy: 0.6862745098039216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zVKCuybitFI7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BERT_extensions_multi_lingual.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
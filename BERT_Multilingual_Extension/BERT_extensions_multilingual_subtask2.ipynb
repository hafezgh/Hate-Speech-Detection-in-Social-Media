{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hafezgh/Hate-Speech-Detection-in-Social-Media/blob/main/BERT_Multilingual_Extension/BERT_extensions_multilingual_subtask2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4ga5LLSSPQN"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqOFKm6QLoua",
        "outputId": "85877655-6e19-4a84-91b9-2881951788a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.0.47)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (3.4.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.1.96)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.8.0rc4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==3.0.0\n",
        "!pip install emoji\n",
        "import gc\n",
        "import os\n",
        "import emoji as emoji\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from transformers import AutoModel\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import copy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3lx2XKTSOn6",
        "outputId": "56ae5bf1-05ac-4a55-d2c1-d3eaa889d4ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hasoc-fire-2020'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 35 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/suman101112/hasoc-fire-2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuSosYM7cRvu"
      },
      "source": [
        "# Read and prepare data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FEVTapdDccBw",
        "outputId": "d1ed94b2-e867-4717-e250-d6b4f3bb7250"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5e5c6279-b7e0-4718-b649-ceb9363f7c17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.123757e+18</td>\n",
              "      <td>hate wen females hit ah nigga with tht bro ðŸ˜‚ðŸ˜‚,...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_2574</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.123733e+18</td>\n",
              "      <td>RT @airjunebug: When you're from the Bay but y...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_3627</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.123734e+18</td>\n",
              "      <td>RT @DonaldJTrumpJr: Dear Democrats: The Americ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_en_3108</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.126951e+18</td>\n",
              "      <td>RT @SheLoveTimothy: He ainâ€™t on drugs he just ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_3986</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.126864e+18</td>\n",
              "      <td>RT @TavianJordan: Summer â€˜19 Iâ€™m coming for yo...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_en_5152</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e5c6279-b7e0-4718-b649-ceb9363f7c17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e5c6279-b7e0-4718-b649-ceb9363f7c17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e5c6279-b7e0-4718-b649-ceb9363f7c17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       tweet_id  ... language\n",
              "0  1.123757e+18  ...        0\n",
              "1  1.123733e+18  ...        0\n",
              "2  1.123734e+18  ...        0\n",
              "3  1.126951e+18  ...        0\n",
              "4  1.126864e+18  ...        0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "data_en = pd.read_excel(\"/content/hasoc-fire-2020/2020/hasoc_2020_en_train_new_a.xlsx\")\n",
        "data_en_test = pd.read_csv(\"/content/hasoc-fire-2020/2020/english_test_1509.csv\")\n",
        "data_en['language'] = 0\n",
        "data_en_test['language'] = 0\n",
        "data_de = pd.read_excel(\"/content/hasoc-fire-2020/2020/hasoc_2020_de_train_new_a.xlsx\")\n",
        "data_de_test = pd.read_csv(\"/content/hasoc-fire-2020/2020/german_test_1509.csv\")\n",
        "data_de['language'] = 1\n",
        "data_de_test['language'] = 1\n",
        "data_hi = pd.read_excel(\"/content/hasoc-fire-2020/2020/hasoc_2020_hi_train_a.xlsx\")\n",
        "data_hi_test = pd.read_csv(\"/content/hasoc-fire-2020/2020/hindi_test_1509.csv\")\n",
        "data_hi['language'] = 2\n",
        "data_hi_test['language'] = 2\n",
        "\n",
        "data = copy.deepcopy(data_en)\n",
        "data = data.append(data_de, ignore_index=True)\n",
        "data = data.append(data_hi, ignore_index=True)\n",
        "data_test = copy.deepcopy(data_en_test)\n",
        "data_test = data_test.append(data_de_test, ignore_index=True)\n",
        "data_test = data_test.append(data_hi_test, ignore_index=True)\n",
        "\n",
        "labels = data[['task1', 'task2', 'language']]\n",
        "le = LabelEncoder()\n",
        "labels['task1'] = le.fit_transform(labels['task1'])\n",
        "le = LabelEncoder()\n",
        "labels['task2'] = le.fit_transform(labels['task2'])\n",
        "\n",
        "labels_test = data_test[['task1', 'task2', 'language']]\n",
        "le = LabelEncoder()\n",
        "labels_test['task1'] = le.fit_transform(labels_test['task1'])\n",
        "le = LabelEncoder()\n",
        "labels_test['task2'] = le.fit_transform(labels_test['task2'])\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_hEbxWJL0qd"
      },
      "outputs": [],
      "source": [
        "data = data.drop(columns=['tweet_id','task1', 'task2','language','ID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPjKgBj-dsEW"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(data, labels, train_size=0.85, shuffle=True, random_state=2045)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZW8Hv7jk_z9"
      },
      "outputs": [],
      "source": [
        "train_set = X_train['text'].to_list()\n",
        "train_labels1 = y_train['task1'].to_list()\n",
        "train_labels2 = y_train['task2'].to_list()\n",
        "train_langs = y_train['language'].to_list()\n",
        "\n",
        "val_set = X_val['text'].to_list()\n",
        "val_labels1 = y_val['task1'].to_list()\n",
        "val_labels2 = y_val['task2'].to_list()\n",
        "val_langs = y_val['language'].to_list()\n",
        "\n",
        "test_set = data_test['text'].to_list()\n",
        "test_labels1 = labels_test['task1'].to_list()\n",
        "test_labels2 = labels_test['task2'].to_list()\n",
        "test_langs = labels_test['language'].to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJDieo15h1ce"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gO3xhOTncTu0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def pre_process_dataset(values):\n",
        "    new_values = list()\n",
        "    # Emoticons\n",
        "    emoticons = [':-)', ':)', '(:', '(-:', ':))', '((:', ':-D', ':D', 'X-D', 'XD', 'xD', 'xD', '<3', '</3', ':\\*',\n",
        "                 ';-)',\n",
        "                 ';)', ';-D', ';D', '(;', '(-;', ':-(', ':(', '(:', '(-:', ':,(', ':\\'(', ':\"(', ':((', ':D', '=D',\n",
        "                 '=)',\n",
        "                 '(=', '=(', ')=', '=-O', 'O-=', ':o', 'o:', 'O:', 'O:', ':-o', 'o-:', ':P', ':p', ':S', ':s', ':@',\n",
        "                 ':>',\n",
        "                 ':<', '^_^', '^.^', '>.>', 'T_T', 'T-T', '-.-', '*.*', '~.~', ':*', ':-*', 'xP', 'XP', 'XP', 'Xp',\n",
        "                 ':-|',\n",
        "                 ':->', ':-<', '$_$', '8-)', ':-P', ':-p', '=P', '=p', ':*)', '*-*', 'B-)', 'O.o', 'X-(', ')-X']\n",
        "\n",
        "    for value in values:\n",
        "        # Remove dots\n",
        "        text = value.replace(\".\", \"\").lower()\n",
        "        text = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", text)\n",
        "        users = re.findall(\"[@]\\w+\", text)\n",
        "        for user in users:\n",
        "            text = text.replace(user, \"<user>\")\n",
        "        urls = re.findall(r'(https?://[^\\s]+)', text)\n",
        "        if len(urls) != 0:\n",
        "            for url in urls:\n",
        "                text = text.replace(url, \"<url >\")\n",
        "        for emo in text:\n",
        "            if emo in emoji.UNICODE_EMOJI:\n",
        "                text = text.replace(emo, \"<emoticon >\")\n",
        "        for emo in emoticons:\n",
        "            text = text.replace(emo, \"<emoticon >\")\n",
        "        numbers = re.findall('[0-9]+', text)\n",
        "        for number in numbers:\n",
        "            text = text.replace(number, \"<number >\")\n",
        "        text = text.replace('#', \"<hashtag >\")\n",
        "        text = re.sub(r\"([?.!,Â¿])\", r\" \", text)\n",
        "        text = \"\".join(l for l in text if l not in string.punctuation)\n",
        "        text = re.sub(r'[\" \"]+', \" \", text)\n",
        "        new_values.append(text)\n",
        "    return new_values\n",
        "\n",
        "\n",
        "def data_process(data, labels):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "    for sentence in data:\n",
        "        bert_inp = bert_tokenizer.__call__(sentence, max_length=64,\n",
        "                                           padding='max_length', pad_to_max_length=True,\n",
        "                                           truncation=True, return_token_type_ids=False)\n",
        "\n",
        "        input_ids.append(bert_inp['input_ids'])\n",
        "        attention_masks.append(bert_inp['attention_mask'])\n",
        "    input_ids = np.asarray(input_ids)\n",
        "    attention_masks = np.array(attention_masks)\n",
        "    labels = np.array(labels)\n",
        "    return input_ids, attention_masks, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32c0j8mp3Jzz"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUcU4tEVLvun"
      },
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert, n_classes, mode='cnn'):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "        self.n_classes = n_classes\n",
        "        self.mode = mode\n",
        "\n",
        "        if mode == 'cnn':\n",
        "            # CNN\n",
        "            self.conv = nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(3, 768), padding='valid')\n",
        "            self.relu = nn.ReLU()\n",
        "            self.pool = nn.MaxPool2d(kernel_size=(3, 1), stride=1)\n",
        "            self.dropout = nn.Dropout(0.1)\n",
        "            self.fc = nn.Linear(13 * (64 - 4), self.n_classes).to(device)\n",
        "            self.flat = nn.Flatten()\n",
        "            \n",
        "        elif mode == 'rnn':\n",
        "            ### RNN\n",
        "            self.lstm = nn.LSTM(768, 256, batch_first=True, bidirectional=True)\n",
        "            ## FC\n",
        "            self.fc = nn.Linear(256*2, self.n_classes)\n",
        "        elif mode == 'shallow_fc':\n",
        "            self.fc = nn.Linear(768, self.n_classes)\n",
        "        elif mode == 'deep_fc':\n",
        "            self.leaky_relu = nn.LeakyReLU(0.01)\n",
        "            self.fc1 = nn.Linear(768, 768)\n",
        "            self.dropout = nn.Dropout(0.1)\n",
        "            self.fc2 = nn.Linear(768, 768)\n",
        "            self.dropout = nn.Dropout(0.1)\n",
        "            self.fc3 = nn.Linear(768, self.n_classes)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Unsupported extension!\")\n",
        "\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        sequence_output, _, all_layers = self.bert(sent_id, attention_mask=mask, output_hidden_states=True)\n",
        "        if self.mode == 'cnn':\n",
        "            x = torch.transpose(torch.cat(tuple([t.unsqueeze(0) for t in all_layers]), 0), 0, 1)\n",
        "            x = self.pool(self.dropout(self.relu(self.conv(self.dropout(x)))))\n",
        "            x = self.fc(self.dropout(self.flat(self.dropout(x))))\n",
        "        elif self.mode == 'rnn':\n",
        "            lstm_output, (h,c) = self.lstm(sequence_output)\n",
        "            hidden = torch.cat((lstm_output[:,-1, :256],lstm_output[:,0, 256:]),dim=-1)\n",
        "            x  = self.fc(hidden.view(-1,256*2))\n",
        "        elif self.mode == 'shallow_fc':\n",
        "            x = self.fc(sequence_output[:,0,:])\n",
        "        elif self.mode == 'deep_fc':\n",
        "            x = self.fc1(sequence_output[:,0,:])\n",
        "            x = self.leaky_relu(x)\n",
        "            x = self.fc2(x)\n",
        "            x = self.leaky_relu(x)\n",
        "            x = self.fc3(x)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Unsupported extension!\")\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        del all_layers\n",
        "        c = self.softmax(x)\n",
        "        return c\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v8P9TN4So5Y"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1fcW3fcia33"
      },
      "outputs": [],
      "source": [
        "\n",
        "# function to train the model\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    total = len(train_dataloader)\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "        step = i+1\n",
        "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
        "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
        "        filledLength = int(100 * step // total)\n",
        "        bar = 'â–ˆ' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
        "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # append the model predictions\n",
        "        total_preds.append(preds.detach().cpu().numpy())\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / (len(train_dataloader)*batch_size)\n",
        "\n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    # returns the loss and predictions\n",
        "    return avg_loss, total_preds\n",
        "\n",
        "\n",
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "    print(\"\\n\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    total = len(val_dataloader)\n",
        "    for i, batch in enumerate(val_dataloader):\n",
        "        \n",
        "        step = i+1\n",
        "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
        "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
        "        filledLength = int(100 * step // total)\n",
        "        bar = 'â–ˆ' * filledLength + '>' * (filledLength < 100) + '.' * (99 - filledLength)\n",
        "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds, labels)\n",
        "\n",
        "            total_loss += float(loss.item())\n",
        "\n",
        "            \n",
        "            total_preds.append(preds.detach().cpu().numpy())\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / (len(val_dataloader)*batch_size)\n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y3L2lH1mROW"
      },
      "outputs": [],
      "source": [
        "### Extension mode\n",
        "MODE = 'rnn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe5O3NoS3cWp"
      },
      "outputs": [],
      "source": [
        "pre_pro_train_data = pre_process_dataset(train_set)\n",
        "pre_pro_val_data = pre_process_dataset(val_set)\n",
        "pre_pro_test_data = pre_process_dataset(test_set)\n",
        "\n",
        "train_input_ids, train_attention_masks, train_labels = data_process(pre_pro_train_data,train_labels2)\n",
        "val_input_ids, val_attention_masks, val_labels = data_process(pre_pro_val_data,val_labels2)\n",
        "test_input_ids, test_attention_masks, test_labels = data_process(pre_pro_test_data,test_labels2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH3HDzr9WDgY",
        "outputId": "20b8af8e-ddd5-48f7-d580-12b1bec37c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Specify the GPU\n",
        "# Setting up the device for GPU usage\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "train_count = len(train_labels)\n",
        "test_count = len(test_labels)\n",
        "val_count = len(val_labels)\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~ Import BERT Model ~~~~~~~~~~~~~~~~~~~~~#\n",
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-multilingual-cased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUtglOzvL6bU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Tokenization ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "# for train set\n",
        "train_seq = torch.tensor(train_input_ids.tolist())\n",
        "train_mask = torch.tensor(train_attention_masks.tolist())\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(val_input_ids.tolist())\n",
        "val_mask = torch.tensor(val_attention_masks.tolist())\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(test_input_ids.tolist())\n",
        "test_mask = torch.tensor(test_attention_masks.tolist())\n",
        "test_y = torch.tensor(test_labels.tolist())\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Create DataLoaders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Freeze BERT Parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert, n_classes=4, mode=MODE)\n",
        "# push the model to GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# loss function\n",
        "cross_entropy = nn.NLLLoss()\n",
        "\n",
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "    # number of training epochs\n",
        "epochs = 3\n",
        "current = 1\n",
        "# for each epoch\n",
        "while current <= epochs:\n",
        "\n",
        "    print(f'\\nEpoch {current} / {epochs}:')\n",
        "\n",
        "    # train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "\n",
        "    print(f'\\n\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    current = current + 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIyWdkPISOp8"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmwow4GrZlfA"
      },
      "outputs": [],
      "source": [
        "# get predictions for test data\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for i in range(len(test_seq)):\n",
        "        pred = model(test_seq[i].unsqueeze(0).to(device), test_mask[i].unsqueeze(0).to(device)).detach().cpu().numpy()\n",
        "        preds.append(pred[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Performance:\")\n",
        "# model's performance\n",
        "preds = np.argmax(preds, axis=1)\n",
        "print('Classification Report (Overall)')\n",
        "print(classification_report(test_y, preds))\n",
        "\n",
        "print(\"Accuracy: \" + str(accuracy_score(test_y, preds)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcPBJ9ivk-io",
        "outputId": "25afd939-a440-47d7-e047-cd8ba6260f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance:\n",
            "Classification Report (Overall)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       105\n",
            "           1       0.80      0.97      0.88      1285\n",
            "           2       0.60      0.01      0.03       205\n",
            "           3       0.75      0.82      0.78       408\n",
            "\n",
            "    accuracy                           0.79      2003\n",
            "   macro avg       0.54      0.45      0.42      2003\n",
            "weighted avg       0.73      0.79      0.73      2003\n",
            "\n",
            "Accuracy: 0.7918122815776335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(test_y, preds, labels=[0,1,2,3])\n",
        "disp_cm = ConfusionMatrixDisplay(cm, display_labels = ['HATE', 'NONE', 'OFFN', 'PRFN'])\n",
        "disp_cm.plot(cmap='Blues')"
      ],
      "metadata": {
        "id": "reVSvrCtvsEV",
        "outputId": "fc7b158e-aa45-4839-882f-9580a0460dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f7c4a41f8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAEGCAYAAADVFgZ3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV1f3/8dc7CbsQkURkE1xwQVQKURAVcUNQvqK2VdG61W9xt1/cqfandWlRq1arYqkb1hWXulIFUdxBFikKogIKssgmsggIST6/P2YCl5jlJpmbO7n5PH3Mw5kz22cIfHLmzJkzMjOcc85FIyvdATjnXCbxpOqccxHypOqccxHypOqccxHypOqccxHKSXcAtSEvL886duyU7jAiV1icuT03crKU7hBSInN/YvDJtKkrzCy/uvtnt+hoVrghqW1tw/I3zKx/dc+VSvUiqXbs2IkPJk1JdxiRW71+c7pDSJncpg3SHUJKFGfwL8JmjbLm12R/K9xAoz1PTmrbjdPvy6vJuVKpXiRV51xdIFDdb5H0pOqciwcBWdnpjqLGPKk65+JDdb8t3ZOqcy4mMuP2v+5fgXMuc0jJTZUeRg9LWibps4Sy2yXNljRD0r8lbZ+wbpikOZK+kHRMQnn/sGyOpGuSuQRPqs65eBBBTTWZqXKPAqW7XI0DuprZfsCXwDAASV2AU4F9wn3ul5QtKRu4DxgAdAEGh9tWyJOqcy4mkqylJlFTNbN3ge9LlY01s8JwcSLQPpwfBDxtZj+Z2dfAHODAcJpjZvPMbBPwdLhthbxN1TkXH8k//c+TlNj5fKSZjazCmX4LPBPOtyNIsiUWhmUA35Yq71nZgT2pOudiokoPqlaYWUG1ziJdCxQCT1Rn/8p4UnXOxYNIeZcqSWcDA4EjbesI/YuADgmbtQ/LqKC8XN6m6pyLj+geVP380FJ/4CrgeDNbn7DqZeBUSY0k7QJ0Bj4GJgOdJe0iqSHBw6yXKzuP11SdczERXT9VSU8BfQnaXhcC1xM87W8EjFNQI55oZueb2UxJo4FZBM0CF5lZUXici4E3gGzgYTObWdm5Pak65+JBQHY0r6ma2eAyih+qYPtbgFvKKB8DjKnKuT2pOufiw19Tdc65qGTGa6qeVJ1z8eE1Veeci5DXVJ1zLiJJvoIad55UnXPx4YNUO+dcVPxBlXPORSsDbv/r/q+FGHnzw1kc8Msb6X7iDdz16Nh0h1MjDz/3Dv3OvpWjzxrOQ8++A8APa37kN5eNoO9pt/Cby0aweu36So4Sbxff+Did+13DQaf8rM93nXPJTU+wZ/9hHDz4zz9bd98T42nV8xJW/rAuDZFVQbTjqaZNrUQnaV2p5bMl3VuqbLqkp8P5c8Ll6ZI2Sfo0nB8e7rs8Yf30ZAaOTbWiomKuvG00z959IRNHX8fzY6cye96SdIdVLV/MW8LTr07kpQeG8p+HruStj2byzcLljHhiPL17dGbCk9fSu0dn7n9ifLpDrZHBA3vx3D0XpTuMSAwe2JPRf7vwZ+WLlq7i7Umzab9TyzREVVXypBoVSXsTvFt7qKRmZvaImXUzs27AYuDwcLnkcwbPlKwPp1lpCz40deY37Nohj07t82jYIIeTju7OmHdmpDusapkzfynd9u5Ik8YNycnJpuf+u/P6uzMY98Fn/Kr/AQD8qv8BjHv/0zRHWjMHd9+dli2apjuMSPT+RdnXcu1dL3DDxYNQXbmtzspOboqxWCRVYDDwL2AsSYysHUdLlq+mXeuttYG2rVuyZPnqNEZUfXvu0obJM+axavWPbNi4ibcnzmLJsh9YvmotO7bKBSB/hxYsX7U2zZG6iox5ZwZt8nPpukf7yjeOi4hG/k+n2npQ1UTS9ITlHdh2CK1TgKOBvYBLgCcrOd4pkg5JWD7IzDZEEqlj906tOf+0Izjjigdo2rghXXZvR1b2tr9/JSHi/Ze7Plu/cRN3jRrL83WpeUP+9L8qNoS38sCWgWILwvkCglG8F0haBDwsaQcz+77sQwHB7f/FFZ1Q0hBgCECHnXeuafyVapOfy6Klq7YsL166ijb5uSk/b6qcclwvTjmuFwC3jXyNNvm55LdszrKVq9mxVS7LVq4mr+V2aY7SleebhStYsHglfX4zHIDFy37g8DNvY9wjV9C6VYs0R1eBmNdCkxGHXwuDgb0kfQPMBVoAv6zpQc1spJkVmFlBfl5+TQ9Xqe5dOjJ3wXLmL1rBps2FvDBuGgP67Jfy86bKivDWftHSVbz+3gyOP6oHRx3cledenwzAc69P5uiDu6YzRFeBLru35YvX/8L0F//E9Bf/RNsdt+ftx66Kd0IlvANKYoqztPZTlZQFnAzsa2aLw7LDgT8C/0xnbFWVk5PNbVedzC8vvY+iIuP043ux925t0h1WtV3wx0dYtWY9OTnZ3PR/vyS3eRMuOO1ILrphFKNfm0S7nVpy3w1npTvMGjn32kf4YOpXrPxhHfscdx3XDDmWMwb1TndY1fK76x7hg2lzWPnDOroO/CPXDDmW3xx/ULrDqpLgayrxTpjJ0NbPtKTwJNI6M9suYflsgtv/Z4FbzaxXwrpsgu/A/MLMloQ12AIzW5Gw7+1s+62YC83sw/LO36NHgX0waUp5q+us1es3pzuElMlt2iDdIaREcXHq/72lS7NGWVOr+zE+gOwddrEmR12f1LY/PntOjc6VSrVSU01MqOHyo8Cj4WKvUuuKgJ0SljtVsK9zLoNkQk3VX1N1zsWGJ1XnnIuQJ1XnnIuKwqmO86TqnIsFEf/uUsnwpOqci42srDh0na8ZT6rOudjwmqpzzkUlQ9pU635d2zmXMaJ6TVXSw5KWSfosoWwHSeMkfRX+v2VYLkn3SJojaYak7gn7nBVu/5WkpF4h9KTqnIuFkgdVEb37/yjQv1TZNcB4M+sMjA+XAQYAncNpCDACgiQMXA/0BA4Eri9JxBXxpOqciw1lKampMmb2LlB6pLtBwKhwfhRwQkL5YxaYCGwvqQ1wDDDOzL43s1XAOH6eqH/G21Sdc/GglD+oam1mJd84+g5oHc63A75N2G5hWFZeeYU8qTrnYqMKSTVPUuIoSSPNbGSyO5uZSUrJ6DaeVJ1zsVGFpLqiGqNULZXUJhz9rg2wLCxfBHRI2K59WLYI6FuqfEJlJ/E2VedcLET8oKosLwMlT/DPAl5KKD8z7AXQC1gdNhO8AfST1DJ8QNUvLKuQ11Sdc/ERUZOqpKcIapl5khYSPMUfDoyWdC4wn2CAfIAxwLHAHGA9cA6AmX0v6SZgcrjdjZV85gnwpOqciwtF95qqmQ0uZ9WRZWxrQJlfSDSzh4GHq3JuT6rOudjw11Sdcy5KdT+nelJ1zsWH11Sdcy4ideHz08nwpOqciw1Pqi6tOh02NN0hpMyqyfemO4SUKMzgT1RHIZn3+uPOk6pzLja8puqcc1FJ/YAqtcKTqnMuFgRkQE71pOqciwt/+u+cc5HK8gdVzjkXEfntv3PORUZ4TdU55yLlNVXnnIuQP6hyzrmoeJuqc85FRyiyQarTyZOqcy42vKbqnHMR8jZV55yLirepOudcdIJ3/+t+VvWk6pyLjQzIqZ5UnXPx4W9UOedcVHw8Veeci46Pp+qcc5HKjPFU6/7rC865jCElNyV3LA2VNFPSZ5KektRY0i6SJkmaI+kZSQ3DbRuFy3PC9Z2qew2eVJ1z8aDgQVUyU6WHktoBlwIFZtYVyAZOBW4F7jKz3YFVwLnhLucCq8Lyu8LtqsWTqnMuFkr6qSYzJSkHaCIpB2gKLAGOAJ4L148CTgjnB4XLhOuPVDXbIrxNNUJvfjiLYXc8R1FxMWcM6s3Qs/ulO6QK/f2Pp3PMIV1ZsWotvU/9MwA3XnoCxxzalc2bi/h64QouuvFx1qzbsGWf9q1b8tHo67j1n2O49/HxAFww+HDOOKE3mDFrzmIuuvFxftpUmJZrqoqLb3ycN97/jLyWzfnomWvTHU6NbPxpM4MuuJtNmwspKipm4OHduOp3x2Jm/OUfr/HKW5+QnZXFWScdwu9OPizd4ZarCnksT9KUhOWRZjayZMHMFkn6K7AA2ACMBaYCP5hZyV/OhUC7cL4d8G24b6Gk1UArYEVVryFlNVVJJumOhOUrJN2QsDxE0uxw+ljSIQnrJiT+gUkqkDQhnO8rabWk6QnTUam6jmQVFRVz5W2jefbuC5k4+jqeHzuV2fOWpDusCj316kR+del925S9PWk2vU/9M4ec9hfmLljGZaV+Mdw89CTe/HDmluU2+bmcd8phHHHmbfQ+9c9kZWVxUr8etRJ/TQ0e2Ivn7rko3WFEolHDHF649xLe/tc1jH/sat6a+DlTPvuap1+bxOKlq/jg6Wt5/+lrOeGo7ukOtUJVaFNdYWYFCdPIbY+jlgS1z12AtkAzoH9tXEMqb/9/Ak6SlFd6haSBwHnAIWa2F3A+8KSknRI221HSgHKO/Z6ZdUuY3ow8+iqaOvMbdu2QR6f2eTRskMNJR3dnzDsz0h1WhT78ZC6r1qzfpuztSbMpKioGYPJnX9O29fZb1h172H4sWLyS2fO+22afnJxsGjdqQHZ2Fk0bN+S75atTH3wEDu6+Oy1bNE13GJGQRLOmjQDYXFhEYWERknj0hfe5/Lf9twypl79D83SGWakIb/+PAr42s+Vmthl4ATgY2D5sDgBoDywK5xcBHcIYcoBcYGV1riGVSbUQGAkMLWPd1cCVZrYCwMymEbRnJFYbbgfqzD3ZkuWrade65Zbltq1bsqSOJJfy/Ob4g3jzw1kANGvSkN+feTS3/nPMNtssWb6avz8+nk9fuYnZ/7mFNT9u4O1Js9MRbr1XVFTMEWfeyj7H/oHDDtyTHvt0Yv6iFbw4fhr9zrmdwUNHMO/bZekOs3xJ1lKTbCFYAPSS1DRsGz0SmAW8Dfwq3OYs4KVw/uVwmXD9W2Zm1bmMVD+oug84XVJuqfJ9CNo3Ek0Jy0t8BGySdHgZxz201O3/bqU3CJsXpkiasnzF8ppcQ710+TnHUFhYzOj/TAbg6iHHMeKpt/hxw6Zttstt3oRj++xLt0HXs/eAa2nauCEnDzggHSHXe9nZWbz12NVMf+lGps2az+dzF/PT5kIaN2zA2Eeu5DeDevN/tzyZ7jDLFQxSHc3TfzObRPDAaRrwKUGuG0lQobtM0hyCNtOHwl0eAlqF5ZcB11T3OlL6oMrM1kh6jKBrw4bKti/DzcB1BH8Qid4zs4GVnHskwR8iPXoUVOs3TlW0yc9l0dJVW5YXL11Fm/zSv0vqhsEDe9LvkK6ccOE9W8oK9unIoCO68adLTiC3eROKi42fftrMsu/XMn/xSlb+sA6AV97+Lwfut8uWZOxqX27zphzSvTNvT/yctvnbc2zf/YGg+eb3Nz+R5ugqlhVh538zux64vlTxPODAMrbdCPw6ivPWRpeqvxH0AWuWUDYLKP00owcwM7HAzN4CmgC9UhlgFLp36cjcBcuZv2gFmzYX8sK4aQzos1+6w6qyIw/am0vPOIrTLv8HG37avKX82CF/Y/9B17P/oOsZ8dQE7nx0LP989l0Wfvc9BfvuQpNGDQA47IA9+eLrpekKv95asWotq9cG7eMbNm7inclfsHvH1vQ/bD8+mPolAB9+Mofddt4xnWFWKsrO/+mS8i5VZva9pNEEifXhsPg24FZJ/c1spaRuwNlAzzIOcTPwAMFvmNjKycnmtqtO5peX3kdRkXH68b3Ye7c26Q6rQg/efDYH9+hMq+2347NXb2L4yDEMPbsfjRrm8O/7LgZgyqffcNnwp8s9xtSZ83l5/CdMePxqioqKmfHFQkb9+4PauoQaOffaR/hg6les/GEd+xx3HdcMOZYzBvVOd1jVsnTlGi698XGKio1iMwYd0Y1+h3Sl5/67cuENj/GPpyfQrGkj7hw2ON2hlksZMqCKqtkWW/mBpXVmtl043xr4GrjNzG4Iyy4A/g8wYC1wuZm9G66bAFxhZlPC5anAWjPrK6kvQePy1wmnu9nMnqMcPXoU2AeTppS3us5qecDF6Q4hZVZNvjfdIaTEpsLidIeQMrlNsqeaWUG19++4t/W+5tGktn39wl41OlcqlVtTlfR3goRXJjO7tKIDlyTUcH4pwRsNietHACPK2bdvqeUeCfMTCLo7OOcyTKaPp5p5VTvnXGyJoAdAXVduUjWzUYnLkpqa2frytnfOuZrKgIpq5U//JR0kaRYwO1zeX9L9KY/MOVe/JPk2VdwfZiXTpepvwDGEr2yZ2X+BPqkMyjlXP9WbLlVm9m2p3w5FqQnHOVdfiWg7/6dLMkn1W0m9AZPUAPg98Hlqw3LO1UeZ8PQ/mdv/8wkGOmkHLAa6se3AJ845V2PJ3vrHvTJbaU01HEnq9FqIxTlXz2XC7X8yT/93lfSKpOWSlkl6SdKutRGcc65+UZJTnCVz+/8kMBpoQzCC9rPAU6kMyjlXP9WXLlVNzexfZlYYTo8DjVMdmHOufgme/ic3xVlF7/7vEM7+R9I1wNMEYwGcAowpbz/nnKsWJTcAddxV9KBqKkESLbnK8xLWGTAsVUE55+qnuN/aJ6Oid/93qc1AnHP1W8ntf12X1BtVkroCXUhoSzWzx1IVlHOufsrommoJSdcDfQmS6hhgAPA+4EnVORepup9Sk3v6/yuCz7t+Z2bnAPvjg0Q75yImQXaWkpriLJnb/w1mViypUFILYBnQIcVxOefqoXpx+w9MkbQ98E+CHgHrgI9SGpVzrl7KgJya1Lv/F4azD0h6HWhhZjNSG5Zzrr4Ryoh3/yvq/N+9onVmNi01ITnn6qU6MAJVMiqqqd5RwToDjog4FldFX7z513SH4KqosChzP1EdhYxuUzWzw2szEOdc/SYgO8KkGj4LehDoSlAR/C3wBfAM0An4BjjZzFYpyOZ3A8cC64Gzq3s3nkyXKuecqxURD6hyN/C6me1F0BX0c+AaYLyZdQbGh8sQ9L/vHE5DgBHVvobq7uicc1GLKqlKyiX4QOlDAGa2ycx+AAYBo8LNRgEnhPODgMcsMBHYXlKbal1DdXZyzrmoBZ9KSXo81TxJUxKmIaUOtwuwHHhE0ieSHpTUDGhtZkvCbb4DWofz7YBvE/ZfGJZVWTKvqYrgcyq7mtmNknYGdjKzj6tzQuecK08Vbu1XmFlBBetzgO7AJWY2SdLdbL3VB8DMTJJVK9AKJFNTvR84CBgcLq8F7os6EOeci/DDfwuBhWY2KVx+jiDJLi25rQ//vyxcv4ht3xRtH5ZVWTJJtaeZXQRsBDCzVUDD6pzMOefKIyBHSmqqjJl9B3wrac+w6EhgFvAycFZYdhbwUjj/MnCmAr2A1QnNBFWSzGuqmyVlE3RJQFI+4J3tnHORi7ib6iXAE5IaAvOAcwgqkqMlnQvMB04Otx1D0J1qDkGXqnOqe9Jkkuo9wL+BHSXdQjBq1XXVPaFzzpVFivY1VTObDpTV7npkGdsacFEU503m3f8nJE0NAxFwgpl9HsXJnXMuUQa8UJXU0/+dCarDrySWmdmCVAbmnKt/Yj5UalKSuf1/ja0fAGxM0P/rC2CfFMblnKtnBLEfgDoZydz+75u4HI5edWE5mzvnXPVU7RXU2Erqw3+JzGyapJ6pCMY5V78pA75SlUyb6mUJi1kEHWgXpywi51y9VJ8+Ud08Yb6QoI31+dSE45yrzzI+qYad/pub2RW1FI9zrh7L6EGqJeWYWaGkg2szIOdc/RR8ojrdUdRcRTXVjwnaT6dLehl4FvixZKWZvZDi2Jxz9UxGf/gvQWNgJcE3qUr6qxrgSdU5F5n68KBqx/DJ/2dsTaYlIh+D0DnnMqCiWmFSzQa2gzI7jnlSdc5FTGRleD/VJWZ2Y61FkgHe/HAWw+54jqLiYs4Y1JuhZ/dLd0hJG3b7M0yYNItW22/Hqw9euc26h5+dwK3/eJWPnv8TO+Q2w8y45b6XeOfjz2ncqCHDrzqFfTq3T1Pk1bfxp80cN+Rv/LS5kKLCIo4/8hcMO++4dIdVbavXrueKW5/hi3lLkOCOYYP5zzszGPfBTBo2yKZj2zzu/MNgcps3TXeoZRKZUVOt6FlbZJcnqb2klyR9JWmupLslNZTUV9JqSdPD6c1w+xskLUooHx6WT5A0JeG4BZImRBVnTRQVFXPlbaN59u4LmTj6Op4fO5XZ86o1xm1anHRMAQ/+5Xc/K1+y7Ac+mPIlbXfcfkvZux/P5ptFyxk76hpuGvorbri7bnZbbtQwh5dGXMr7Tw7j3SeHMf6jWUz+9Ot0h1Vt/+/uf3N4z71498k/MO7Rq+jcsTV9DtiTtx67mjdHXc2uHfK5919vpjvM8glyspTUFGcVJdWfjTlYHeE3rl4AXgw/C7sHQbPCLeEm75lZt3A6KmHXuxLKE78ts6OkAVHEFqWpM79h1w55dGqfR8MGOZx0dHfGvDMj3WEl7YD9diuzBvOXES9x5ZCB2/QfHP/hTE44ugBJdOvSkTXrNrJs5ZraDDcSktiuaSMANhcWsbmwqM72k1yzbgOT/juXwQN7AdCwQQ65zZty2IF7kZOTDUD3fTqxZPnqdIZZoZKaakSfU0mbcpOqmX0f0TmOADaa2SPhcYuAocBvgerch9wOXBtRbJFZsnw17Vq33LLctnXLWP8FTsabH3zGjnm57LVb223Kl65YzU75W2uuO+XnsnRF3bzWoqJiDj3tL+zR7xr69tyLgq6d0h1StSxYspJW22/H0D8/Sb9zbueK4U+zfsNP22zz9GuTOLzX3mmKMDlZ4UDVlU1xVhtdbfcBpiYWmNkaYAGwO3Bowm1+YrIcmlB+TEL5R8AmSYdXdFJJQ0o+X7t8xfKILqX+2LBxE/94ajy/P+uYyjeuw7Kzs3jvyWHMfO1mps2cz6w5dXNYi6KiYj79ciFnnnAwYx+5kqaNG3Lv4+O3rL971FhysrM4qV+PNEZZuYyuqdaixNv/WxLKE2//3yi1z81U8kkXMxtpZgVmVpCflx950KW1yc9l0dJVW5YXL11Fm/zclJ83VRYsXsnC775n0Hl3csTpt/Dd8tWcdP5dLP9+Da3zcvlu+Q9btv1u+Wpa59XdawXIbd6UQ3vswfiPZqU7lGppk789bfJz6b5PJwCOO3x/Pv1yIQDPjJnEmx/O5N7rz4h184YIElIyU5zVRnyzgG1+PUpqAexM8JGtKjOzt4AmQK8aRxeR7l06MnfBcuYvWsGmzYW8MG4aA/rsl+6wqm3PXdvw0XN/4q0nruWtJ65lp/xcXnhgKPk7tOCIg7rw4rgpmBnTZ82nebPG7NiqRbpDrrIVq9ayeu16IKiZv/3xbDp3ap3mqKpnx1YtaLtjS+YsWArA+1O+ZI9OrXl74ueMePItHh3+O5o0jvlHkJUZt/9VHk+1GsYDwyWdaWaPhYO03AE8SvCZluq6GXiA4CuJaZeTk81tV53MLy+9j6Ii4/Tje7H3bm3SHVbSLrvlcT7+71xWrf6RPqfexCVn9ePXA8oeNvewnnvzzsezOfrM4TRp1IA/X3lKLUcbje9WrOHCG/5FUXExxcXGiUd1p/+h+1a+Y0zdNPQkLvnT42wuLGTntq24c9hpHPe7O/lpcyGnDr0fCB5W3XrlyZUcKT2CN6rinTCToeAjgik+idQBuB/Yi6B2PAa4AjgIuMLMBpba/gZgnZn9tVT5hHD7KeHyVGCtmfWt6Pw9ehTYB5OmVLRJnbRs9cZ0h5AyO+Y2TncIKbH+p8J0h5AyrbZrMNXMyvp6aVJ27bKf3fSvMUlt+5uCDjU6VyrVRk0VM/sW+J8yVk0Ip9Lb31DOcfqWWo53q7tzrkoyoKJaO0nVOecqp1g/SEuWJ1XnXCyUPP2v6zypOudiIxMeVGXCLwbnXCZQ8OpwMlPSh5SyJX0i6dVweRdJkyTNkfSMpIZheaNweU64vlN1L8OTqnMuFlLU+f/3wOcJy7cSvFi0O7AKODcsPxdYFZbfFW5XLZ5UnXOxEWVNVVJ74DjgwXBZBGORPBduMgo4IZwfFC4Trj9S1Xxq5knVORcbSnIC8krG9ginIWUc7m/AVUBxuNwK+MHMSjoLLwTahfPtgG8BwvWrw+2rzB9UOediQUB28pXDFRV1/pc0EFhmZlMl9Y0gvKR5UnXOxUaED/8PBo6XdCzBx0tbAHcD20vKCWuj7YFF4faLgA7AQkk5QC7BB0+rzG//nXMxoaT/q4yZDTOz9mbWCTgVeMvMTgfeBn4VbnYW8FI4/3K4TLj+LavmO/yeVJ1zsVEL46leDVwmaQ5Bm+lDYflDQKuw/DLgmnL2r5Tf/jvnYiHoUhV9538zm0A4xoiZzQMOLGObjcCvozifJ1XnXDzUgVH9k+FJ1TkXG5nwmqonVedcLASDVKc7iprzpOqci41knuzHnSdV51xsZMDdvydV51x8eE3VOeci4m2qzjkXpTrw+elkeFJ1zsVG3U+pnlTrtGaN/MdX13y6cE26Q4it4Pa/7qdV/1fpnIuNup9SPak65+IkA7KqJ1XnXGz47b9zzkWo7qdUT6rOuTjJgKzqSdU5FwvBR/3qflb1pOqciwcfT9U556KVATnVk6pzLi6EMqCq6knVORcbGZBTPak65+JB+O2/c85FKwOyqidV51xseJcq55yLkLepOudcVLyfqnPORSsTbv+z0h2Ac85B+PRfyU2VHkvqIOltSbMkzZT0+7B8B0njJH0V/r9lWC5J90iaI2mGpO7VvQ5Pqs652FCSUxIKgcvNrAvQC7hIUhfgGmC8mXUGxofLAAOAzuE0BBhR3WvwpOqci4+IsqqZLTGzaeH8WuBzoB0wCBgVbjYKOCGcHwQ8ZoGJwPaS2lTnErxN1TkXG1UYpDpP0pSE5ZFmNrKsDSV1An4BTAJam9mScNV3QOtwvh3wbcJuC8OyJVSRJ1XnXGxU4THVCjMrqPR40nbA88D/mdmaxLEFzMwkWTXCrJDf/jvn4iPCRlVJDQgS6hNm9kJYvLTktj78/7KwfBHQIWH39mFZlXlNNUJvfjiLYXc8R1FxMWcM6s3Qs/ulO6RqmbtgKRdcP2rL8oLFK7ni3AGsWrOeN977lKwskdeyOXf+4TR2ystNY6Q1V5d/Zps2beaKP890MuIAAA2ASURBVD3M5s2FFBUXc2jPfTjj10dw5wMv8tW8RRjQfqdWXH7hiTRp3IixEz7hoSfeoNUOLQD4n2N6MuCIHum9iARRDlKtoEr6EPC5md2ZsOpl4CxgePj/lxLKL5b0NNATWJ3QTFAltZJUJRUBn4bn+xw4y8zWlyr/GjjDzH4I20A+B75IOMyBwGnAw0A3M5sRHvszYKCZfVMb11KeoqJirrxtNP++92Latt6eI866nQF99mWvXavV1p1Wu+3cmrGPXAUE11Vw0vX077Mfuc2bcuX/HgvAQ8+9w98efYPhV5yczlBrpK7/zBo0yOHWP55Nk8aNKCws4vLrH6SgW2fOO7M/zZo2BuAfj/2Hl9+YxCmD+gDQ56CuXPTbgekMu3zRdv4/GDgD+FTS9LDsDwTJdLSkc4H5QMlf4DHAscAcYD1wTnVPXFs11Q1m1g1A0hPA+cCdpcpHARcBt4T7zC1ZVyJsD1kIXAucUjuhJ2fqzG/YtUMendrnAXDS0d0Z886MOvMPtDzvT/2Sjm3zaL/TDtuUb9iwqc53067rPzNJNGncCIDCoiIKi4oRbEmoZsamTYV1qkN9VJGa2fsVHO7IMrY3gvxTY+m4/X8P2K+M8o/KKS/tVaCPpD3N7ItKt64lS5avpl3rlluW27ZuydTPvklfQBF5efw0Bh21tR/0rSNf47k3JtOiWWNG331xGiOruUz4mRUVF3PJsAdY/N33/E+/A9mrc9AseMeIfzN5+pfs3C6f351xzJbt3/94Fp/Onk/7nVpx3pkDyI9V801mDFJdqw+qJOUQdLL9tFR5NsFvj5cTineTND2c7ksoLwZuI6jKuxTatLmQsR/MZODhW28Yrh5yHJOfv4ETj+7BIy+8l8boHEB2Vhb333ohj99/OV/MXcg33y4F4PILTuSJEVeyc7t83v3oMwB69diTUX+/jAduu4hf7Lcbfx3xQkWHTouo3qhKp9pKqk3Cdo0pwAKCBuTE8pL+YuMS9plrZt3CqXS1/Emgl6RdyjuhpCGSpkiasnzF8uiupBxt8nNZtHTVluXFS1fRJj9OtYCqe3vi5+y7R3vyd2j+s3Un9ivgP+/8Nw1RRSeTfmbbNWvC/vvswpTpX20py87K4rDe+/L+pFkAtGjelIYNgpvT/kf04Kt5i9MSa3mSffAf85xaa0l1Q0KCvMTMNiWWAx0J/qySatMws0LgDuDqCrYZaWYFZlaQn5df0/gr1b1LR+YuWM78RSvYtLmQF8ZNY0CfZFoz4uulN6cx6Mitt/7zvt36y+mN9z5lt51bl7VbnVHXf2Y/rPmRdT9uAOCnTZuZNmMu7dvmsfi7lUDQpjpxymw6tA3ajFeuWrtl34lTZrNzu9T/u6iyDMiqsehSFfYEuBR4UdL9Se72KHAV8PNqVBrk5GRz21Un88tL76OoyDj9+F7svVvdeOBRlvUbfuLdKV8w/MqtT/f/8o9XmLdgGZJov9MO/OWKX6cxwpqr6z+z71et5Y4RL1BUbFix0eegfTjwF3twxQ0PsX7DT5jBrh134uJzg6f9L70+kYlTZ5OdlUXz7Zpw+QUnpvkKfq4uPVQrj4KHXik+ibTOzLarrFzSK8BogodZr5pZ11Lbnw0UmNnF4fKlwN3ALhV1qerRo8A+mDSlvNV11o8bC9MdQso0axyL3/eRmzT3+3SHkDJ992o1NZm3nMqzX7ce9upbHya1bcdWjWt0rlSqlb+5ZSXUssrN7H8SFruW2hwze5SghlqyfA9wTyRBOufSS5BV9yuq8bj9d865QN3Pqp5UnXOxUDJIdV3nSdU5FxsZkFM9qTrn4sNrqs45F6FMeE3Vk6pzLjbqfkr1pOqci4m68F5/MjypOudiIxPeqPKk6pyLj7qfUz2pOufiIwNyqidV51xcqCqfqI4tT6rOuVjIlDeq/BPVzjkXIa+pOudiIxNqqp5UnXOx4V2qnHMuKt753znnopMpD6o8qTrnYsNv/51zLkKZUFP1LlXOudiI8gvVkvpL+kLSHEnXpCLesnhSdc7FR0RZVVI2cB8wAOgCDJbUJSUxl+JJ1TkXCwKypKSmJBwIzDGzeWa2CXgaGJTK+EvUizbVadOmrmjSQPNr6XR5wIpaOldty9Rr8+uKRsea7Dxt2tQ3mjRQXpKbN5Y0JWF5pJmNTFhuB3ybsLwQ6FmT+JJVL5KqmeXX1rkkTTGzgto6X23K1Gvz64oHM+uf7hii4Lf/zrlMtAjokLDcPixLOU+qzrlMNBnoLGkXSQ2BU4GXa+PE9eL2v5aNrHyTOitTr82vK8OYWaGki4E3gGzgYTObWRvnlpnVxnmcc65e8Nt/55yLkCdV55yLkCfVSkhaV2r5bEn3liqbLunpcP6ccHm6pE2SPg3nh4f7Lk9YP7223vIoFa9JuiNh+QpJNyQsD5E0O5w+lnRIwroJif0DJRVImhDO95W0utT1HVU7V7WVpPaSXpL0laS5ku6W1LCM+N4Mt79B0qKE8uGVXWs6SCoK4/tM0rOSmpZR/oqk7cPyTpI2lPp5NAz/HhZL2i/h2J9J6pSeK8ssnlRrSNLeBA3hh0pqZmaPmFk3M+sGLAYOD5dL3j1+pmR9OM1KQ9g/ASdJP+9oLWkgcB5wiJntBZwPPClpp4TNdpQ0oJxjv1fq+t6MPPoKSBLwAvCimXUG9gC2A24pI77EhH9XQnnie+IVXWtt2xDG1xXYRPCzKV3+PXBRwj5zS/08NoXlC4Fray/0+sOTas0NBv4FjKWWXoOLQCHBk+GhZay7GrjSzFYAmNk0YBTb/kO9nfj+gzwC2GhmjwCYWRHBdf4WaFqN48X1Wt8Ddi+j/COCt4kq8yqwj6Q9I43KeVJNQpPE2yfgxlLrTyF4r/gpggRbmVNK3Y41iTrgJN0HnC4pt1T5PsDUUmVTwvISHwGbJB1exnEPLXV9u0UXclJ+Fr+ZrQEWECShxPgSk+XQhPJjEsoruta0kJRDMFDIp6XKs4Ej2bY/5m4J13VfQnkxcBvwh1THW994P9XKbQhv5YGgTRUoCOcLgBVmtkDSIuBhSTuY2fcVHO8ZM7s4pREnwczWSHoMuBTYUI1D3AxcR1CzTfSemQ2saXwpVF58d5nZX8vZp7xrrW1Nwl/sENRUHypV3g74HBiXsM/cxL+/pTwJXCtpl5REW095TbVmBgN7SfoGmAu0AH6Z1oiq5m/AuUCzhLJZQI9S2/UAtuk4bWZvAU2AXqkMsBp+Fr+kFsDOwJzqHDBG17ohoW30koT20ZJf/B0JBnu6qPxDbGVmhcAdpP+XRUbxpFpNkrKAk4F9zayTmXUiaFNNpgkgFsIa9WiCxFriNuBWSa0AJHUDzgbuL+MQNwNXpTjMqhoPNJV0Jmy5Jb4DeBRYX4PjxvFat2Fm6wnuPC4PmwiS8ShwFFBrgw5lOk+q1XcosMjMFieUvQt0kdSmgv1Kt6n2Tm2YlbqDYIg4AMzsZeBh4ENJs4F/Ar8xsyWldzSzMcDyUsWl21R/lcLYf8aCVwRPBH4t6SvgS2AjNWw7LOdaY8fMPgFmkOQv97C2ew+wYyrjqk/8NVXnnIuQ11Sdcy5CnlSdcy5CnlSdcy5CnlSdcy5CnlSdcy5CnlQdUP4ISNU81qMlXakkPagKRuIKR46qcrcySd+UMyBMmeWltllX0foytr9B0hVVjdHVT55UXYnyRkACtrxvXmVm9r+VjMTVF0h3X13nIuNJ1ZXlPWD3sBb5nqSXgVmSsiXdLmmypBmSzoNguD1J90r6IhyjdEtH8nBM0pKxEvpLmibpv5LGh+N3ns/WwUwOlZQv6fnwHJMlHRzu20rSWEkzJT1I8DpmhSS9KGlquM+QUuvuCsvHS8oPy3aT9Hq4z3uS9oriD9PVLz6gittGwghIr4dF3YGuZvZ1mJhWm9kBkhoBH0gaC/wC2BPoArQmeP/+4VLHzSd4O6tPeKwdzOx7SQ8A60oGM5H0JMHgJu9L2pngw217A9cD75vZjZKOY9tXa8vz2/AcTYDJkp43s5UEYx1MMbOhkv5feOyLCYZDPN/MvpLUk+DV3COq8cfo6jFPqq5EWSMg9QY+NrOvw/J+wH4Jr57mAp2BPsBT4diliyW9VcbxewHvlhyrgpG8jiJ41bdkuYWk7cJznBTu+5qkVUlc06WSTgznO4SxriQY9u6ZsPxx4IXwHL2BZxPO3SiJczi3DU+qrsQ2QxwChMnlx8Qi4BIze6PUdsdGGEcW0MvMNpYRS9Ik9SVI0AeZ2XoFn0FpXM7mFp73hwqGyXMuKd6m6qriDeACSQ0AJO0hqRnBQDKnhG2ubYCyBnSeCPQpGbtT0g5h+VqgecJ2Y4FLShbCUbIIz3FaWDYAaFlJrLnAqjCh7sW2w/ZlASW17dMImhXWAF9L+nV4Dknav5JzOPcznlRdVTxI0F46TdJnwD8I7nb+DXwVrnuMYLT8bZjZcmAIwa32f9l6+/0KcGLJgyqCoesKwgdhs9jaC+FPBEl5JkEzwIJKYn0dyJH0OTCcIKmX+BE4MLyGI9j6NYfTgXPD+GZSdz6P42LER6lyzrkIeU3VOeci5EnVOeci5EnVOeci5EnVOeci5EnVOeci5EnVOeci5EnVOeci9P8BThpWfuM0px8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6cJkkC_SQQN"
      },
      "source": [
        "# Post-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL7ASGELSR1v"
      },
      "outputs": [],
      "source": [
        "### Analyze the results by language\n",
        "# HATE: 0, NONE: 1, OFFN: 2, PRFN: 3\n",
        "# Languages, EN: 0, DE: 1, HI: 2\n",
        "\n",
        "test_labels2 = np.array(test_labels2)\n",
        "en_actual = []\n",
        "en_pred = []\n",
        "hi_actual = []\n",
        "hi_pred = []\n",
        "de_actual = []\n",
        "de_pred = []\n",
        "for i in range(len(test_labels)):\n",
        "    if data_test['language'][i] == 0:\n",
        "        en_actual.append(test_labels2[i])\n",
        "        en_pred.append(preds[i])\n",
        "    if data_test['language'][i] == 1:\n",
        "        de_actual.append(test_labels2[i])\n",
        "        de_pred.append(preds[i])\n",
        "    if data_test['language'][i] == 2:\n",
        "        hi_actual.append(test_labels2[i])\n",
        "        hi_pred.append(preds[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# en\n",
        "print('Classification Report (English)')\n",
        "print(classification_report(en_actual, en_pred))\n",
        "print(\"Accuracy: \" + str(accuracy_score(en_actual, en_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b_a7i0ZrE78",
        "outputId": "b9727546-86f5-4c3a-fea2-4d1b0c08e58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (English)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        25\n",
            "           1       0.85      0.96      0.90       414\n",
            "           2       0.50      0.01      0.02        82\n",
            "           3       0.79      0.92      0.85       293\n",
            "\n",
            "    accuracy                           0.82       814\n",
            "   macro avg       0.53      0.47      0.44       814\n",
            "weighted avg       0.76      0.82      0.77       814\n",
            "\n",
            "Accuracy: 0.8206388206388207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# de\n",
        "print('Classification Report (German)')\n",
        "print(classification_report(de_actual, de_pred))\n",
        "print(\"Accuracy: \" + str(accuracy_score(de_actual, de_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eJHFSsyramS",
        "outputId": "28dc8138-a511-4e93-c7f7-ed5195eac837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (German)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        24\n",
            "           1       0.85      0.96      0.90       378\n",
            "           2       0.00      0.00      0.00        36\n",
            "           3       0.64      0.72      0.68        88\n",
            "\n",
            "    accuracy                           0.81       526\n",
            "   macro avg       0.37      0.42      0.39       526\n",
            "weighted avg       0.72      0.81      0.76       526\n",
            "\n",
            "Accuracy: 0.8079847908745247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hi\n",
        "print('Classification Report (Hindi)')\n",
        "print(classification_report(hi_actual, hi_pred))\n",
        "print(\"Accuracy: \" + str(accuracy_score(hi_actual, hi_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGlrxLkarcnA",
        "outputId": "d4eee36a-a0ad-43c9-cd66-99696d66cfab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Hindi)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        56\n",
            "           1       0.75      0.99      0.85       493\n",
            "           2       0.67      0.02      0.04        87\n",
            "           3       0.43      0.11      0.18        27\n",
            "\n",
            "    accuracy                           0.74       663\n",
            "   macro avg       0.46      0.28      0.27       663\n",
            "weighted avg       0.66      0.74      0.65       663\n",
            "\n",
            "Accuracy: 0.7435897435897436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_actual = np.array(en_actual)\n",
        "en_pred = np.array(en_pred)"
      ],
      "metadata": {
        "id": "4vbo5U_PuRzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_en_test[en_actual != en_pred]"
      ],
      "metadata": {
        "id": "1HYkzHIjuSWA",
        "outputId": "94ba5ba4-cd8d-4db9-f65d-b002b8f357e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bf0b0d03-328b-45df-b806-a48cd70320dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1123805971883732993</td>\n",
              "      <td>@TheFrankComin fuck her like itâ€™s the end of t...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_en_1747</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1123772564269084673</td>\n",
              "      <td>RT @NotHoopOverhoes: Youâ€™re not losing because...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_1449</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1123693589693968385</td>\n",
              "      <td>@sammyyyk12 Ummmmm excuse me, you too bitch ðŸŽ“ðŸŽ“...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_en_3086</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1127051318789431296</td>\n",
              "      <td>RT @GiGiHadid: Y'all Niggas On Some Other Shit</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_en_1355</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1130092617046249472</td>\n",
              "      <td>@jiminslovr STFU U TRAITOR</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_420</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>1123653777385562112</td>\n",
              "      <td>@emmyrossum Anacdotal you fucking idiot</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_en_1801</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794</th>\n",
              "      <td>1130327363819118594</td>\n",
              "      <td>@omz__music @CraigLiddell58 @realDonaldTrump I...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_en_284</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>1123728322763083776</td>\n",
              "      <td>If you're happy about the \"virgin killer\" swea...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_en_2559</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>1130319105255305216</td>\n",
              "      <td>RT @DMNug: Jamie Lannister is the nastiest ska...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_en_1857</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810</th>\n",
              "      <td>1123685826074951681</td>\n",
              "      <td>@ThreeDailey Omg heâ€™s so gross! This just turn...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_en_3435</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf0b0d03-328b-45df-b806-a48cd70320dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf0b0d03-328b-45df-b806-a48cd70320dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf0b0d03-328b-45df-b806-a48cd70320dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                tweet_id  ... language\n",
              "6    1123805971883732993  ...        0\n",
              "8    1123772564269084673  ...        0\n",
              "9    1123693589693968385  ...        0\n",
              "11   1127051318789431296  ...        0\n",
              "15   1130092617046249472  ...        0\n",
              "..                   ...  ...      ...\n",
              "786  1123653777385562112  ...        0\n",
              "794  1130327363819118594  ...        0\n",
              "800  1123728322763083776  ...        0\n",
              "801  1130319105255305216  ...        0\n",
              "810  1123685826074951681  ...        0\n",
              "\n",
              "[146 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 801\n",
        "print(en_actual[i], en_pred[i])\n",
        "print(data_en_test['text'][i])"
      ],
      "metadata": {
        "id": "Ni3l3oR7uVmW",
        "outputId": "f79092f4-47d7-46fb-aff4-851dd2adec1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 3\n",
            "RT @DMNug: Jamie Lannister is the nastiest skank bitch I have ever met. Do not trust him, he is a fugly slut. #GameofThrones #GOT https://tâ€¦\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HATE: 0, NONE: 1, OFFN: 2, PRFN: 3"
      ],
      "metadata": {
        "id": "J6TYinapuo4P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BERT_extensions_multi_lingual.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Clin_Trials_on_Cancer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e6c6b6fe3b7434e8bca8ca635fd80f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b7aab1ce47fd411b9077e6b197bb1c78",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e1ca3c612e64c88914b6a45fa000955",
              "IPY_MODEL_1cd621d09b714f5c92581c8ef301252d",
              "IPY_MODEL_7bea5474438c4017a38578bb235c654c"
            ]
          }
        },
        "b7aab1ce47fd411b9077e6b197bb1c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e1ca3c612e64c88914b6a45fa000955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c5e77b1730145bd8b858bdd52dff8b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_742b84e9335d4d2ea8b7f406ac717296"
          }
        },
        "1cd621d09b714f5c92581c8ef301252d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_669ba8b50fef4a6599772b63a12cbce3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 489,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 489,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbd8c1f3e26149c1b9bcaaca2ac10643"
          }
        },
        "7bea5474438c4017a38578bb235c654c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d27ef23dc0e44d00b97e331d14aa1fcd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 489/489 [16:48&lt;00:00,  1.65s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cebb18d7a8c0451ab30a6e508f0980d5"
          }
        },
        "7c5e77b1730145bd8b858bdd52dff8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "742b84e9335d4d2ea8b7f406ac717296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "669ba8b50fef4a6599772b63a12cbce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbd8c1f3e26149c1b9bcaaca2ac10643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d27ef23dc0e44d00b97e331d14aa1fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cebb18d7a8c0451ab30a6e508f0980d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "zL9RLHo4YfCP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CS8RvR92lNT5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install datasets metrics transformers wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers.file_utils import ModelOutput\n",
        "from datasets import Dataset\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import torch\n",
        "import gc"
      ],
      "metadata": {
        "id": "rPEgvdLiYOij"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Cw6BRBvc3gH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom BERT model"
      ],
      "metadata": {
        "id": "PScS_63IYhzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, model_name='bert-base-uncased', device='cuda'):\n",
        "        super(BERTCNN, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(3, 768), padding='valid').to(device)\n",
        "        self.relu = nn.ReLU()\n",
        "        # change the kernel size either to (3,1), e.g. 1D max pooling\n",
        "        # or remove it altogether\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(3, 1), stride=1).to(device)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        # be careful here, this needs to be changed according to your max pooling\n",
        "        # without pooling: 443, with 3x1 pooling: 416\n",
        "        # FC\n",
        "        self.fc = nn.Linear(598, 3).to(device) ## 416, 66004???\n",
        "        self.flat = nn.Flatten()\n",
        "        self.softmax = nn.LogSoftmax(dim=1).to(device)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            output_hidden_states=True)\n",
        "        x = torch.transpose(torch.cat(tuple([t.unsqueeze(0) for t in outputs[2]]), 0), 0, 1)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        c = self.softmax(x)\n",
        "\n",
        "        # Clean cache\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        del outputs\n",
        "\n",
        "        # Compute loss\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            ce_loss = nn.CrossEntropyLoss()\n",
        "            loss = ce_loss(c, labels)\n",
        "\n",
        "        return ModelOutput({\n",
        "            'loss': loss,\n",
        "            'last_hidden_state': c\n",
        "        })\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "model = BERTCNN(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUVqrd6Jlfqy",
        "outputId": "222fe3f6-fd19-4fa7-ab05-accff2437d83"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-procesing"
      ],
      "metadata": {
        "id": "MNH27sMbYno4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data_to_model_inputs(batch):\n",
        "    # tokenize the inputs and labels\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        batch[\"1\"],\n",
        "        max_length=50,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "    labels = list(map(lambda x: int(x.split('__label__')[1]), batch['0']))\n",
        "    batch[\"label\"] = labels\n",
        "\n",
        "    return batch\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  # calculate f1 using sklearn's function\n",
        "  f_score = f1_score(labels, preds, pos_label=0, average='binary')\n",
        "  accuracy = accuracy_score(labels, preds)\n",
        "  precision = precision_score(labels, preds, pos_label=0, average='binary')\n",
        "  recall = recall_score(labels, preds, pos_label=0, average='binary')\n",
        "  return {\n",
        "      'f1_score': f_score,\n",
        "      'accuracy': accuracy,\n",
        "      'precision': precision,\n",
        "      'recall': recall\n",
        "  }\n",
        "    \n",
        "tokenize_batch_size = 2048\n",
        "df = pd.read_csv('/content/drive/MyDrive/PoliTo/Deep Natural Language Procesing/Project/labeledEligibilitySample1000000.csv', sep='\\t', header=None)"
      ],
      "metadata": {
        "id": "3CS9g-WOoj4H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = Dataset.from_pandas(df)\n",
        "\n",
        "train_ds = train_ds.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=tokenize_batch_size,\n",
        "    remove_columns=[\"0\", \"1\"]\n",
        ")\n",
        "\n",
        "train_ds.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3e6c6b6fe3b7434e8bca8ca635fd80f7",
            "b7aab1ce47fd411b9077e6b197bb1c78",
            "9e1ca3c612e64c88914b6a45fa000955",
            "1cd621d09b714f5c92581c8ef301252d",
            "7bea5474438c4017a38578bb235c654c",
            "7c5e77b1730145bd8b858bdd52dff8b3",
            "742b84e9335d4d2ea8b7f406ac717296",
            "669ba8b50fef4a6599772b63a12cbce3",
            "dbd8c1f3e26149c1b9bcaaca2ac10643",
            "d27ef23dc0e44d00b97e331d14aa1fcd",
            "cebb18d7a8c0451ab30a6e508f0980d5"
          ]
        },
        "id": "botUA7zqLsFS",
        "outputId": "f45ae991-ffcf-4be9-d463-248bd9e77e44"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e6c6b6fe3b7434e8bca8ca635fd80f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/489 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_testvalid = train_ds.train_test_split(train_size=0.9)\n",
        "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)"
      ],
      "metadata": {
        "id": "gfupyDfSR_1Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and evaluation"
      ],
      "metadata": {
        "id": "cS-joqbuY9pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./CNN_CTC_results',          # output directory\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=128,  # batch size per device during training\n",
        "    per_device_eval_batch_size=128,   # batch size for evaluation\n",
        "    fp16=True,                       # enable fp16 apex training\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
        "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
        "    logging_steps=400,               # log & save weights each logging_steps\n",
        "    save_steps=400,\n",
        "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
        "    report_to=\"wandb\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_testvalid['train'],         # training dataset\n",
        "    eval_dataset=test_valid['train'],          # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "preds = trainer.predict(test_valid['test'])\n",
        "\n",
        "preds[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ND48bydf0ypB",
        "outputId": "5edfdcfc-2825-41b8-c38f-c3b3b532b6a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 400\n",
            "PyTorch: setting up devices\n",
            "Using amp half precision backend\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 900000\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 14064\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14064' max='14064' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14064/14064 14:13:03, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.522600</td>\n",
              "      <td>0.311992</td>\n",
              "      <td>0.874965</td>\n",
              "      <td>0.875120</td>\n",
              "      <td>0.883600</td>\n",
              "      <td>0.866497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.296400</td>\n",
              "      <td>0.262327</td>\n",
              "      <td>0.891582</td>\n",
              "      <td>0.895320</td>\n",
              "      <td>0.933140</td>\n",
              "      <td>0.853568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.257600</td>\n",
              "      <td>0.235711</td>\n",
              "      <td>0.912008</td>\n",
              "      <td>0.911040</td>\n",
              "      <td>0.909776</td>\n",
              "      <td>0.914251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.240900</td>\n",
              "      <td>0.226032</td>\n",
              "      <td>0.908008</td>\n",
              "      <td>0.910440</td>\n",
              "      <td>0.941828</td>\n",
              "      <td>0.876532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.225400</td>\n",
              "      <td>0.209773</td>\n",
              "      <td>0.918621</td>\n",
              "      <td>0.919080</td>\n",
              "      <td>0.931891</td>\n",
              "      <td>0.905723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.211300</td>\n",
              "      <td>0.215528</td>\n",
              "      <td>0.918779</td>\n",
              "      <td>0.920280</td>\n",
              "      <td>0.944768</td>\n",
              "      <td>0.894182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.207600</td>\n",
              "      <td>0.199680</td>\n",
              "      <td>0.923408</td>\n",
              "      <td>0.924540</td>\n",
              "      <td>0.945775</td>\n",
              "      <td>0.902074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.201900</td>\n",
              "      <td>0.193069</td>\n",
              "      <td>0.925392</td>\n",
              "      <td>0.925740</td>\n",
              "      <td>0.937811</td>\n",
              "      <td>0.913299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.192500</td>\n",
              "      <td>0.191086</td>\n",
              "      <td>0.929916</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.939054</td>\n",
              "      <td>0.920953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.186100</td>\n",
              "      <td>0.180500</td>\n",
              "      <td>0.932717</td>\n",
              "      <td>0.932500</td>\n",
              "      <td>0.937670</td>\n",
              "      <td>0.927815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.184100</td>\n",
              "      <td>0.175152</td>\n",
              "      <td>0.934042</td>\n",
              "      <td>0.934440</td>\n",
              "      <td>0.947927</td>\n",
              "      <td>0.920557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.181400</td>\n",
              "      <td>0.167460</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.937440</td>\n",
              "      <td>0.946288</td>\n",
              "      <td>0.928648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.172800</td>\n",
              "      <td>0.167409</td>\n",
              "      <td>0.936297</td>\n",
              "      <td>0.936660</td>\n",
              "      <td>0.949882</td>\n",
              "      <td>0.923095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.172200</td>\n",
              "      <td>0.166369</td>\n",
              "      <td>0.939733</td>\n",
              "      <td>0.939300</td>\n",
              "      <td>0.940985</td>\n",
              "      <td>0.938484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.171900</td>\n",
              "      <td>0.163359</td>\n",
              "      <td>0.939677</td>\n",
              "      <td>0.939520</td>\n",
              "      <td>0.945258</td>\n",
              "      <td>0.934161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.166100</td>\n",
              "      <td>0.162004</td>\n",
              "      <td>0.938465</td>\n",
              "      <td>0.939120</td>\n",
              "      <td>0.956999</td>\n",
              "      <td>0.920636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.160100</td>\n",
              "      <td>0.157146</td>\n",
              "      <td>0.941871</td>\n",
              "      <td>0.941680</td>\n",
              "      <td>0.946816</td>\n",
              "      <td>0.936977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.146400</td>\n",
              "      <td>0.159271</td>\n",
              "      <td>0.940999</td>\n",
              "      <td>0.941360</td>\n",
              "      <td>0.955067</td>\n",
              "      <td>0.927339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.135200</td>\n",
              "      <td>0.157794</td>\n",
              "      <td>0.942171</td>\n",
              "      <td>0.942660</td>\n",
              "      <td>0.958586</td>\n",
              "      <td>0.926308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.133900</td>\n",
              "      <td>0.153444</td>\n",
              "      <td>0.944387</td>\n",
              "      <td>0.944480</td>\n",
              "      <td>0.954135</td>\n",
              "      <td>0.934835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.135300</td>\n",
              "      <td>0.150038</td>\n",
              "      <td>0.945136</td>\n",
              "      <td>0.945060</td>\n",
              "      <td>0.951923</td>\n",
              "      <td>0.938444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.129400</td>\n",
              "      <td>0.152865</td>\n",
              "      <td>0.945614</td>\n",
              "      <td>0.945780</td>\n",
              "      <td>0.956726</td>\n",
              "      <td>0.934756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.125700</td>\n",
              "      <td>0.151339</td>\n",
              "      <td>0.946150</td>\n",
              "      <td>0.946300</td>\n",
              "      <td>0.956994</td>\n",
              "      <td>0.935549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.131000</td>\n",
              "      <td>0.142470</td>\n",
              "      <td>0.947576</td>\n",
              "      <td>0.947480</td>\n",
              "      <td>0.953937</td>\n",
              "      <td>0.941300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.125600</td>\n",
              "      <td>0.141764</td>\n",
              "      <td>0.948055</td>\n",
              "      <td>0.948220</td>\n",
              "      <td>0.959315</td>\n",
              "      <td>0.937056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.120900</td>\n",
              "      <td>0.141197</td>\n",
              "      <td>0.949410</td>\n",
              "      <td>0.949460</td>\n",
              "      <td>0.958525</td>\n",
              "      <td>0.940467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.123300</td>\n",
              "      <td>0.142877</td>\n",
              "      <td>0.948975</td>\n",
              "      <td>0.949320</td>\n",
              "      <td>0.963802</td>\n",
              "      <td>0.934597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.119400</td>\n",
              "      <td>0.142168</td>\n",
              "      <td>0.949724</td>\n",
              "      <td>0.949980</td>\n",
              "      <td>0.962906</td>\n",
              "      <td>0.936898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.119100</td>\n",
              "      <td>0.139988</td>\n",
              "      <td>0.951012</td>\n",
              "      <td>0.951060</td>\n",
              "      <td>0.960142</td>\n",
              "      <td>0.942054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.118700</td>\n",
              "      <td>0.137577</td>\n",
              "      <td>0.951540</td>\n",
              "      <td>0.951620</td>\n",
              "      <td>0.961342</td>\n",
              "      <td>0.941935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12400</td>\n",
              "      <td>0.115600</td>\n",
              "      <td>0.135435</td>\n",
              "      <td>0.951990</td>\n",
              "      <td>0.952080</td>\n",
              "      <td>0.962014</td>\n",
              "      <td>0.942173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12800</td>\n",
              "      <td>0.112200</td>\n",
              "      <td>0.135873</td>\n",
              "      <td>0.951635</td>\n",
              "      <td>0.951860</td>\n",
              "      <td>0.964405</td>\n",
              "      <td>0.939198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13200</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.134378</td>\n",
              "      <td>0.952624</td>\n",
              "      <td>0.952800</td>\n",
              "      <td>0.964473</td>\n",
              "      <td>0.941062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13600</td>\n",
              "      <td>0.112500</td>\n",
              "      <td>0.132579</td>\n",
              "      <td>0.952913</td>\n",
              "      <td>0.952980</td>\n",
              "      <td>0.962494</td>\n",
              "      <td>0.943521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.115700</td>\n",
              "      <td>0.131884</td>\n",
              "      <td>0.952922</td>\n",
              "      <td>0.953060</td>\n",
              "      <td>0.964002</td>\n",
              "      <td>0.942093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-400\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-800\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-1200\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-1600\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-2400\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-2800\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-3200\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-3600\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-4400\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-4800\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-5200\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-5600\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-6400\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-6800\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-7200\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-7600\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-8000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-8400\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-8800\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-9200\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-9600\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-10000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-10400\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-10800\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-11200\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-11600\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-12000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-12400\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-12800\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-13200\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-13600\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./CNN_CTC_results/checkpoint-14000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./CNN_CTC_results/checkpoint-14000 (score: 0.1318841278553009).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 50000\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='391' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [391/391 01:54]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_accuracy': 0.95522,\n",
              " 'test_f1_score': 0.9548306401178155,\n",
              " 'test_loss': 0.12351412326097488,\n",
              " 'test_precision': 0.9629313151041666,\n",
              " 'test_recall': 0.9468651222342256,\n",
              " 'test_runtime': 114.4118,\n",
              " 'test_samples_per_second': 437.018,\n",
              " 'test_steps_per_second': 3.417}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.save(trainer.model, '/content/drive/MyDrive/PoliTo/Deep Natural Language Procesing/Project/model.model')"
      ],
      "metadata": {
        "id": "nrZpBwXZWQEH"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}